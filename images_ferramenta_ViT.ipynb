{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/visionCodes/blob/master/images_ferramenta_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgVtPmABT7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R_KVCjoCBc4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "pziXvdPgU58B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Images"
      ],
      "metadata": {
        "id": "4GQRp3F5Hbob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/ferramenta/ImagesDataset/\"\n",
        "# images-train.tar.gz\n",
        "# images-val.tar.gz"
      ],
      "metadata": {
        "id": "W1xklJs8BdI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "KTqYpi4zBq-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tarfile\n",
        "\n",
        "# with tarfile.open('images-train.tar.gz', 'r:gz') as tar_ref:\n",
        "#     tar_ref.extractall('trainImages')"
      ],
      "metadata": {
        "id": "k0NsL1RqFdl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FragmentaDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "        self.num_classes = len(self.dataset.classes)\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     image, label = self.dataset[index]\n",
        "    #     return image, label\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        while True:\n",
        "            try:\n",
        "                image, label = self.dataset[index]\n",
        "                return image, label\n",
        "            except (UnidentifiedImageError, FileNotFoundError) as e:\n",
        "                print(f\"Error loading image at index {index}: {e}\")\n",
        "                index += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_num_classes(self):\n",
        "        return self.num_classes"
      ],
      "metadata": {
        "id": "SxiZcLMwIdP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_lengths_dict = val_dataset.class_lengths\n",
        "total_sum = sum(class_lengths_dict.values())\n",
        "dict_length = len(class_lengths_dict)\n",
        "\n",
        "# Print the length\n",
        "print(\"Dictionary length:\", dict_length)\n",
        "# Print the total sum\n",
        "print(\"Total sum:\", total_sum)\n",
        "print(class_lengths_dict.values())"
      ],
      "metadata": {
        "id": "gn3WwWQZ9I6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimeting with ViT\n"
      ],
      "metadata": {
        "id": "itFOnF65mjy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification"
      ],
      "metadata": {
        "id": "-ifwsPDemn5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image processor\n",
        "processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
      ],
      "metadata": {
        "id": "5G16wzIEnu4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image transforms\n",
        "image_size = processor.model.config.image_size\n",
        "normalize = transforms.Normalize(mean=processor.model.config.mean, std=processor.model.config.std)"
      ],
      "metadata": {
        "id": "yKB5MZTTnxdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ],
      "metadata": {
        "id": "tv5xXUkYnzbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"\"\n",
        "val_dir = \"\""
      ],
      "metadata": {
        "id": "EAmZ-pcrU7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and validation datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset = ImageFolder(val_dir, transform=val_transforms)"
      ],
      "metadata": {
        "id": "ox4u3_5Zn34m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Training samples:\", len(train_dataset))\n",
        "print(\"Number of Training classes:\", len(train_dataset.classes))\n",
        "\n",
        "print(\"Number of Vaidation samples:\", len(val_dataset))\n",
        "print(\"Number of Vaidation classes:\", len(val_dataset.classes))"
      ],
      "metadata": {
        "id": "JOA0x3uekTwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the collate function for data loading\n",
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    labels = torch.tensor([item[1] for item in batch])\n",
        "    images = torch.stack(images)\n",
        "    return {\"pixel_values\": images, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "I0_m7XPTn5ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and validation\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "e5SnKRojn9A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ViT model\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')\n"
      ],
      "metadata": {
        "id": "-rYsad9noAmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "pKMDSOC_oBFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 5\n",
        "training_losses = []"
      ],
      "metadata": {
        "id": "TCsJ86NjoCwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pixel_values=images).logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    training_losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "8VAkW6asoFlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curve\n",
        "plt.plot(range(1, num_epochs+1), training_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eWVnlT-rVWlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test dataset\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(pixel_values=images).logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= len(val_loader)\n",
        "test_accuracy = correct_predictions / len(val_loader) * 100\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "2vE7yUtToTsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_U-5SQtVTEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "wo8vOzPcj0vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "8AGPTxfAj24x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "mNGI9ipNj3sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels for the metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "# Define the values for each metric\n",
        "values = [accuracy, precision, recall, f1]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(metrics, values)\n",
        "plt.ylim([0, 1])  # Set the y-axis limit to range from 0 to 1\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Evaluation Metrics')\n",
        "\n",
        "# Add the metric scores on top of each bar\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 4), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EU0kUaoRj7X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each label in predicted and true labels\n",
        "predicted_counts = np.bincount(predicted_labels)\n",
        "true_counts = np.bincount(true_labels)\n",
        "\n",
        "# Get the unique labels\n",
        "labels = np.unique(np.concatenate((predicted_labels, true_labels)))\n",
        "\n",
        "# Set the x-axis range\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Set the width of the bars\n",
        "width = 0.35\n",
        "\n",
        "# Plot the predicted and true label counts\n",
        "fig, ax = plt.subplots(figsize=(20, 8))\n",
        "ax.bar(x - width/2, predicted_counts, width, label='Predicted Labels')\n",
        "ax.bar(x + width/2, true_counts, width, label='True Labels')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Labels')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Distribution of Predicted and True Labels')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K5mUPcr_jtdA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}