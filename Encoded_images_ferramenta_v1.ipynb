{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/visionCodes/blob/master/Encoded_images_ferramenta_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgVtPmABT7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R_KVCjoCBc4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "pziXvdPgU58B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Images"
      ],
      "metadata": {
        "id": "4GQRp3F5Hbob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/ferramenta/ImagesDataset/\"\n",
        "# images-train.tar.gz\n",
        "# images-val.tar.gz"
      ],
      "metadata": {
        "id": "W1xklJs8BdI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "KTqYpi4zBq-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tarfile\n",
        "\n",
        "# with tarfile.open('images-train.tar.gz', 'r:gz') as tar_ref:\n",
        "#     tar_ref.extractall('trainImages')"
      ],
      "metadata": {
        "id": "k0NsL1RqFdl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tarfile\n",
        "\n",
        "# with tarfile.open('images-val.tar.gz', 'r:gz') as tar_ref:\n",
        "#     tar_ref.extractall('validImages')"
      ],
      "metadata": {
        "id": "_53xeTK9hVQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Pre-processing Training Data"
      ],
      "metadata": {
        "id": "8DzB_fXhx9xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    # transforms.RandomRotation(10),  # Randomly rotate the image by a maximum of 10 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "31E1tiyb5XSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FragmentaDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "        self.num_classes = len(self.dataset.classes)\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     image, label = self.dataset[index]\n",
        "    #     return image, label\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        while True:\n",
        "            try:\n",
        "                image, label = self.dataset[index]\n",
        "                return image, label\n",
        "            except (UnidentifiedImageError, FileNotFoundError) as e:\n",
        "                print(f\"Error loading image at index {index}: {e}\")\n",
        "                index += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_num_classes(self):\n",
        "        return self.num_classes"
      ],
      "metadata": {
        "id": "M_dAq8fk6Emp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"\"\n",
        "dataset = FragmentaDataset(data_dir)"
      ],
      "metadata": {
        "id": "9vVrkM4c5hGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(dataset))\n",
        "print(\"Number of classes:\", len(dataset.classes))"
      ],
      "metadata": {
        "id": "FbBNqWRqrRbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_workers = 2\n",
        "batch_size = 32\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "JlFKG_ymv-zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_lengths_dict = dataset.class_lengths\n",
        "total_sum = sum(class_lengths_dict.values())\n",
        "dict_length = len(class_lengths_dict)\n",
        "\n",
        "# Print the length\n",
        "print(\"Dictionary length:\", dict_length)\n",
        "# Print the total sum\n",
        "print(\"Total sum:\", total_sum)\n",
        "print(class_lengths_dict.values())"
      ],
      "metadata": {
        "id": "ZZ5CXhyYnUsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract class labels and counts from the dictionary\n",
        "class_labels = list(class_lengths_dict.keys())\n",
        "class_counts = list(class_lengths_dict.values())\n",
        "\n",
        "# Sort the class labels and counts in ascending order\n",
        "sorted_indices = sorted(range(len(class_counts)), key=lambda k: class_counts[k])\n",
        "class_labels_sorted = [class_labels[i] for i in sorted_indices]\n",
        "class_counts_sorted = [class_counts[i] for i in sorted_indices]\n",
        "\n",
        "# Create a count plot with sorted data\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=class_labels_sorted, y=class_counts_sorted)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Count of Instances in Each Class (Ascending Order)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "99Qg-5PD6xsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "vsW7ms9iFQIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_length = dataset.class_lengths\n",
        "class_labels = list(class_length.keys())"
      ],
      "metadata": {
        "id": "VtJYA2vJ_lzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "def plot_sample_images(dataset):\n",
        "\n",
        "\n",
        "    # Create a grid layout based on the number of classes\n",
        "    num_classes = len(class_length)\n",
        "    grid_cols = 4  # Number of columns in the grid\n",
        "    grid_rows = (num_classes + grid_cols - 1) // grid_cols  # Number of rows in the grid\n",
        "    plt.figure(figsize=(10, 5 * grid_rows))\n",
        "\n",
        "    # Create a transform to convert the tensor to PIL Image\n",
        "    to_pil = ToPILImage()\n",
        "\n",
        "    # Iterate over each class\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        # Get a random image index from the class\n",
        "        image_index = np.random.choice(class_length[class_label])\n",
        "\n",
        "        # Get the image and label from the dataset\n",
        "        image, label = dataset[image_index]\n",
        "\n",
        "        # Convert the image tensor to PIL Image\n",
        "        image = to_pil(image)\n",
        "\n",
        "        # Plot the image\n",
        "        plt.subplot(grid_rows, grid_cols, i + 1)\n",
        "        plt.imshow(image, interpolation='none')  # Use 'RGB' interpolation\n",
        "        plt.title(class_label)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "mM85nfZA_4KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample_images(dataset)"
      ],
      "metadata": {
        "id": "vmHEUpE2AlP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Fine-Tuning GoogleNet"
      ],
      "metadata": {
        "id": "-6USyg1J7b7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "googlenet = models.googlenet(pretrained=True)"
      ],
      "metadata": {
        "id": "vkL01sw1x_VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(data_loader.dataset.dataset.classes)\n",
        "googlenet.fc = torch.nn.Linear(googlenet.fc.in_features, num_classes)\n",
        "print(googlenet)"
      ],
      "metadata": {
        "id": "FQ349SDOyLXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "googlenet = googlenet.to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "uh9SmmbJyd15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(googlenet.parameters(), lr=0.001, momentum=0.9)\n",
        "num_epochs = 25"
      ],
      "metadata": {
        "id": "jeYHKbJlyh2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "googlenet.train()\n",
        "# Loop over the dataset and train the model\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in data_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = googlenet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader.dataset)\n",
        "    training_losses.append(epoch_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "G2We0NqKypyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/MyDrive/Colab Notebooks/ferramenta/models/GoogleNet_stateDict/\"\n",
        "os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "save_path = os.path.join(save_dir, 'googleNet.pth')  # Specify the complete path to the model file\n",
        "torch.save(googlenet.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "ivRpZ006Q1vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_dir = '/content/drive/MyDrive/Colab Notebooks/ferramenta/models/GoogleNet_30_epoch/'\n",
        "# os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# save_path = os.path.join(save_dir, 'googleNet.pth')  # Specify the complete path to the model file\n",
        "# torch.save(googlenet, save_path)"
      ],
      "metadata": {
        "id": "YdjyYLB-DOoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curve\n",
        "plt.plot(range(1, num_epochs+1), training_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8dlRxo6A1F-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Pre-processing Validation Dataset"
      ],
      "metadata": {
        "id": "qI-_9wOMJf0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "oL5wubV35q7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.dataset = datasets.ImageFolder(data_dir, transform=val_transform)\n",
        "        self.data_dir = data_dir\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     image, label = self.dataset[index]\n",
        "    #     return image, label\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        while True:\n",
        "            try:\n",
        "                image, label = self.dataset[index]\n",
        "                return image, label\n",
        "            except (UnidentifiedImageError, FileNotFoundError) as e:\n",
        "                print(f\"Error loading image at index {index}: {e}\")\n",
        "                index += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "LmECoxcS5s90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valPath = \"/content/drive/MyDrive/Colab Notebooks/ferramenta/ImagesDataset/validImages/images-val\"\n",
        "val_dataset = ValidationDataset(valPath)"
      ],
      "metadata": {
        "id": "-2nH3cah5rmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(val_dataset))\n",
        "print(\"Number of classes:\", len(val_dataset.classes))"
      ],
      "metadata": {
        "id": "PMVyg5k_hpNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "validation_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "n0gyykmIhmon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_lengths_dict = val_dataset.class_lengths\n",
        "total_sum = sum(class_lengths_dict.values())\n",
        "dict_length = len(class_lengths_dict)\n",
        "\n",
        "# Print the length\n",
        "print(\"Dictionary length:\", dict_length)\n",
        "# Print the total sum\n",
        "print(\"Total sum:\", total_sum)\n",
        "print(class_lengths_dict.values())"
      ],
      "metadata": {
        "id": "gn3WwWQZ9I6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract class labels and counts from the dictionary\n",
        "class_labels = list(class_lengths_dict.keys())\n",
        "class_counts = list(class_lengths_dict.values())\n",
        "\n",
        "# Sort the class labels and counts in ascending order\n",
        "sorted_indices = sorted(range(len(class_counts)), key=lambda k: class_counts[k])\n",
        "class_labels_sorted = [class_labels[i] for i in sorted_indices]\n",
        "class_counts_sorted = [class_counts[i] for i in sorted_indices]\n",
        "\n",
        "# Create a count plot with sorted data\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=class_labels_sorted, y=class_counts_sorted)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Count of Instances in Each Class (Ascending Order)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A5w0Ki_V68Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Evaluating Response"
      ],
      "metadata": {
        "id": "ic7kN48N8HWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model path\n",
        "save_dir = \"\"\n",
        "load_path = os.path.join(save_dir, 'model.pth')\n",
        "\n",
        "# Create an instance of the ResNet model\n",
        "googlenet = models.googlenet(pretrained=False)\n",
        "googlenet.fc = nn.Linear(1024, 52)\n",
        "\n",
        "# Load the saved model parameters\n",
        "googlenet.load_state_dict(torch.load(load_path), strict=False)\n",
        "\n",
        "# Set the model to evaluation mode and respective device\n",
        "googlenet.eval()\n",
        "googlenet.to(device)"
      ],
      "metadata": {
        "id": "UGYrLz2h8Og1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluation loop\n",
        "googlenet.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in validation_data_loader:\n",
        "        # Move the images and labels to the GPU if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = googlenet(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        predicted_labels.extend(predicted.cpu().tolist())\n",
        "        true_labels.extend(labels.cpu().tolist())\n"
      ],
      "metadata": {
        "id": "oFEz33gyzQyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "cIdJcRgn1EJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "rg4I5G0K1Gbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels for the metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "# Define the values for each metric\n",
        "values = [accuracy, precision, recall, f1]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(metrics, values)\n",
        "plt.ylim([0, 1])  # Set the y-axis limit to range from 0 to 1\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Evaluation Metrics')\n",
        "\n",
        "# Add the metric scores on top of each bar\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 4), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lU-GeXydXhlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each label in predicted and true labels\n",
        "predicted_counts = np.bincount(predicted_labels)\n",
        "true_counts = np.bincount(true_labels)\n",
        "\n",
        "# Get the unique labels\n",
        "labels = np.unique(np.concatenate((predicted_labels, true_labels)))\n",
        "\n",
        "# Set the x-axis range\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Set the width of the bars\n",
        "width = 0.35\n",
        "\n",
        "# Plot the predicted and true label counts\n",
        "fig, ax = plt.subplots(figsize=(20, 8))\n",
        "ax.bar(x - width/2, predicted_counts, width, label='Predicted Labels')\n",
        "ax.bar(x + width/2, true_counts, width, label='True Labels')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Labels')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Distribution of Predicted and True Labels')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "96tZe80tYUyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IK0PpPKkC3hM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}