{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l9MRZVUDjiR9",
        "EJzF42PYkJZV",
        "aWUpA83OjNdj",
        "Uuv8a8uqis8x",
        "22-x5xhQka64"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYoPsAgXFxnM/tSTTtTXz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/visionCodes/blob/master/Experiment-NTS-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown https://drive.google.com/uc?id=1yny7iVWVIqrNCnUNr5TjjXvZjIg1MAdT"
      ],
      "metadata": {
        "id": "960f9Er_5h39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvzf /content/CUB_200_2011.tgz\n",
        "# !unzip /content/nts-net/mulitmodal.zip"
      ],
      "metadata": {
        "id": "QORzVqNd3R5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "\n",
        "BATCH_SIZE = 8 #16\n",
        "PROPOSAL_NUM = 6\n",
        "CAT_NUM = 4\n",
        "INPUT_SIZE = (256, 256)  # (w, h)\n",
        "LR = 0.001\n",
        "WD = 1e-4\n",
        "SAVE_FREQ = 1\n",
        "resume = ''\n",
        "test_model = '/content/003.ckpt'           # address of test model\n",
        "save_dir = '/content/Models_NTS' # change it to /content/desired_directory"
      ],
      "metadata": {
        "id": "6bZfcqREjhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# anchors.py"
      ],
      "metadata": {
        "id": "l9MRZVUDjiR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# from config import INPUT_SIZE\n",
        "\n",
        "_default_anchors_setting = (\n",
        "    dict(layer='p3', stride=32, size=48, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        "    dict(layer='p4', stride=64, size=96, scale=[2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        "    dict(layer='p5', stride=128, size=192, scale=[1, 2 ** (1. / 3.), 2 ** (2. / 3.)], aspect_ratio=[0.667, 1, 1.5]),\n",
        ")\n",
        "\n",
        "\n",
        "def generate_default_anchor_maps(anchors_setting=None, input_shape=INPUT_SIZE):\n",
        "    \"\"\"\n",
        "    generate default anchor\n",
        "\n",
        "    :param anchors_setting: all informations of anchors\n",
        "    :param input_shape: shape of input images, e.g. (h, w)\n",
        "    :return: center_anchors: # anchors * 4 (oy, ox, h, w)\n",
        "             edge_anchors: # anchors * 4 (y0, x0, y1, x1)\n",
        "             anchor_area: # anchors * 1 (area)\n",
        "    \"\"\"\n",
        "    if anchors_setting is None:\n",
        "        anchors_setting = _default_anchors_setting\n",
        "\n",
        "    center_anchors = np.zeros((0, 4), dtype=np.float32)\n",
        "    edge_anchors = np.zeros((0, 4), dtype=np.float32)\n",
        "    anchor_areas = np.zeros((0,), dtype=np.float32)\n",
        "    input_shape = np.array(input_shape, dtype=int)\n",
        "\n",
        "    for anchor_info in anchors_setting:\n",
        "\n",
        "        stride = anchor_info['stride']\n",
        "        size = anchor_info['size']\n",
        "        scales = anchor_info['scale']\n",
        "        aspect_ratios = anchor_info['aspect_ratio']\n",
        "\n",
        "        output_map_shape = np.ceil(input_shape.astype(np.float32) / stride)\n",
        "        output_map_shape = output_map_shape.astype(np.int)\n",
        "        output_shape = tuple(output_map_shape) + (4,)\n",
        "        ostart = stride / 2.\n",
        "        oy = np.arange(ostart, ostart + stride * output_shape[0], stride)\n",
        "        oy = oy.reshape(output_shape[0], 1)\n",
        "        ox = np.arange(ostart, ostart + stride * output_shape[1], stride)\n",
        "        ox = ox.reshape(1, output_shape[1])\n",
        "        center_anchor_map_template = np.zeros(output_shape, dtype=np.float32)\n",
        "        center_anchor_map_template[:, :, 0] = oy\n",
        "        center_anchor_map_template[:, :, 1] = ox\n",
        "        for scale in scales:\n",
        "            for aspect_ratio in aspect_ratios:\n",
        "                center_anchor_map = center_anchor_map_template.copy()\n",
        "                center_anchor_map[:, :, 2] = size * scale / float(aspect_ratio) ** 0.5\n",
        "                center_anchor_map[:, :, 3] = size * scale * float(aspect_ratio) ** 0.5\n",
        "\n",
        "                edge_anchor_map = np.concatenate((center_anchor_map[..., :2] - center_anchor_map[..., 2:4] / 2.,\n",
        "                                                  center_anchor_map[..., :2] + center_anchor_map[..., 2:4] / 2.),\n",
        "                                                 axis=-1)\n",
        "                anchor_area_map = center_anchor_map[..., 2] * center_anchor_map[..., 3]\n",
        "                center_anchors = np.concatenate((center_anchors, center_anchor_map.reshape(-1, 4)))\n",
        "                edge_anchors = np.concatenate((edge_anchors, edge_anchor_map.reshape(-1, 4)))\n",
        "                anchor_areas = np.concatenate((anchor_areas, anchor_area_map.reshape(-1)))\n",
        "\n",
        "    return center_anchors, edge_anchors, anchor_areas\n",
        "\n",
        "\n",
        "def hard_nms(cdds, topn=10, iou_thresh=0.25):\n",
        "    if not (type(cdds).__module__ == 'numpy' and len(cdds.shape) == 2 and cdds.shape[1] >= 5):\n",
        "        raise TypeError('edge_box_map should be N * 5+ ndarray')\n",
        "\n",
        "    cdds = cdds.copy()\n",
        "    indices = np.argsort(cdds[:, 0])\n",
        "    cdds = cdds[indices]\n",
        "    cdd_results = []\n",
        "\n",
        "    res = cdds\n",
        "\n",
        "    while res.any():\n",
        "        cdd = res[-1]\n",
        "        cdd_results.append(cdd)\n",
        "        if len(cdd_results) == topn:\n",
        "            return np.array(cdd_results)\n",
        "        res = res[:-1]\n",
        "\n",
        "        start_max = np.maximum(res[:, 1:3], cdd[1:3])\n",
        "        end_min = np.minimum(res[:, 3:5], cdd[3:5])\n",
        "        lengths = end_min - start_max\n",
        "        intersec_map = lengths[:, 0] * lengths[:, 1]\n",
        "        intersec_map[np.logical_or(lengths[:, 0] < 0, lengths[:, 1] < 0)] = 0\n",
        "        iou_map_cur = intersec_map / ((res[:, 3] - res[:, 1]) * (res[:, 4] - res[:, 2]) + (cdd[3] - cdd[1]) * (\n",
        "            cdd[4] - cdd[2]) - intersec_map)\n",
        "        res = res[iou_map_cur < iou_thresh]\n",
        "\n",
        "    return np.array(cdd_results)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     a = hard_nms(np.array([\n",
        "#         [0.4, 1, 10, 12, 20],\n",
        "#         [0.5, 1, 11, 11, 20],\n",
        "#         [0.55, 20, 30, 40, 50]\n",
        "#     ]), topn=100, iou_thresh=0.4)\n",
        "#     print(a)\n",
        "a = hard_nms(np.array([\n",
        "        [0.4, 1, 10, 12, 20],\n",
        "        [0.5, 1, 11, 11, 20],\n",
        "        [0.55, 20, 30, 40, 50]\n",
        "    ]), topn=100, iou_thresh=0.4)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_1wTZJIjgzT",
        "outputId": "66b2441b-9e67-4bcc-c377-ca6b382c6918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.55 20.   30.   40.   50.  ]\n",
            " [ 0.5   1.   11.   11.   20.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py"
      ],
      "metadata": {
        "id": "EJzF42PYkJZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# _, term_width = os.popen('stty size', 'r').read().split()\n",
        "try:\n",
        "    output = os.popen('stty size', 'r').read()\n",
        "    rows, columns = map(int, output.split())\n",
        "    term_width = columns\n",
        "except ValueError:\n",
        "    term_width = 80  # Set a default value\n",
        "\n",
        "term_width = int(term_width)\n",
        "\n",
        "TOTAL_BAR_LENGTH = 40.\n",
        "last_time = time.time()\n",
        "begin_time = last_time\n",
        "\n",
        "\n",
        "def progress_bar(current, total, msg=None):\n",
        "    global last_time, begin_time\n",
        "    if current == 0:\n",
        "        begin_time = time.time()  # Reset for new bar.\n",
        "\n",
        "    cur_len = int(TOTAL_BAR_LENGTH * current / total)\n",
        "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
        "\n",
        "    sys.stdout.write(' [')\n",
        "    for i in range(cur_len):\n",
        "        sys.stdout.write('=')\n",
        "    sys.stdout.write('>')\n",
        "    for i in range(rest_len):\n",
        "        sys.stdout.write('.')\n",
        "    sys.stdout.write(']')\n",
        "\n",
        "    cur_time = time.time()\n",
        "    step_time = cur_time - last_time\n",
        "    last_time = cur_time\n",
        "    tot_time = cur_time - begin_time\n",
        "\n",
        "    L = []\n",
        "    L.append('  Step: %s' % format_time(step_time))\n",
        "    L.append(' | Tot: %s' % format_time(tot_time))\n",
        "    if msg:\n",
        "        L.append(' | ' + msg)\n",
        "\n",
        "    msg = ''.join(L)\n",
        "    sys.stdout.write(msg)\n",
        "    for i in range(term_width - int(TOTAL_BAR_LENGTH) - len(msg) - 3):\n",
        "        sys.stdout.write(' ')\n",
        "\n",
        "    # Go back to the center of the bar.\n",
        "    for i in range(term_width - int(TOTAL_BAR_LENGTH / 2)):\n",
        "        sys.stdout.write('\\b')\n",
        "    sys.stdout.write(' %d/%d ' % (current + 1, total))\n",
        "\n",
        "    if current < total - 1:\n",
        "        sys.stdout.write('\\r')\n",
        "    else:\n",
        "        sys.stdout.write('\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600 / 24)\n",
        "    seconds = seconds - days * 3600 * 24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours * 3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes * 60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds * 1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f\n",
        "\n",
        "\n",
        "def init_log(output_dir):\n",
        "    logging.basicConfig(level=logging.DEBUG,\n",
        "                        format='%(asctime)s %(message)s',\n",
        "                        datefmt='%Y%m%d-%H:%M:%S',\n",
        "                        filename=os.path.join(output_dir, 'log.log'),\n",
        "                        filemode='w')\n",
        "    console = logging.StreamHandler()\n",
        "    console.setLevel(logging.INFO)\n",
        "    logging.getLogger('').addHandler(console)\n",
        "    return logging\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass"
      ],
      "metadata": {
        "id": "wjQ3hVVwkKc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset.py"
      ],
      "metadata": {
        "id": "E7nn2-5QhZC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade scipy"
      ],
      "metadata": {
        "id": "JkyaOeK38vEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scipy==1.1.0"
      ],
      "metadata": {
        "id": "6WJLcGio9dO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DAqfGup_i7b",
        "outputId": "dbbb3d11-20b1-4688-f517-d7da708d6814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.22.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.misc\n",
        "import os\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from torchvision import transforms\n",
        "# from config import INPUT_SIZE\n",
        "\n",
        "images_path = \"/content/mulitmodal/images.txt\"\n",
        "image_class_labels_path = \"/content/mulitmodal/image_class_labels.txt\"\n",
        "train_test_split_path = \"/content/mulitmodal/train_test_split.txt\"\n",
        "\n",
        "class CUB():\n",
        "    def __init__(self, root, is_train=True, data_len=None):\n",
        "        self.root = root\n",
        "        self.is_train = is_train\n",
        "\n",
        "        img_txt_file = open(os.path.join(self.root, images_path))\n",
        "        label_txt_file = open(os.path.join(self.root, image_class_labels_path))\n",
        "        train_val_file = open(os.path.join(self.root, train_test_split_path))\n",
        "\n",
        "        img_name_list = []\n",
        "        for line in img_txt_file:\n",
        "            img_name_list.append(line[:-1].split(' ')[-1])\n",
        "        label_list = []\n",
        "        for line in label_txt_file:\n",
        "            label_list.append(int(line[:-1].split(' ')[-1]) - 1)\n",
        "        train_test_list = []\n",
        "        for line in train_val_file:\n",
        "            train_test_list.append(int(line[:-1].split(' ')[-1]))\n",
        "\n",
        "\n",
        "        train_file_list = [x for i, x in zip(train_test_list, img_name_list) if i]\n",
        "        test_file_list = [x for i, x in zip(train_test_list, img_name_list) if not i]\n",
        "\n",
        "\n",
        "        if self.is_train:\n",
        "            # self.train_img = [\n",
        "            #     np.array(Image.open(os.path.join(self.root, 'images', train_file)).convert('RGB'))\n",
        "            #     for train_file in train_file_list[:data_len]]\n",
        "            self.train_img = [imageio.imread(os.path.join(self.root, 'images', train_file)) for train_file in\n",
        "                              train_file_list[:data_len]]\n",
        "            self.train_label = [x for i, x in zip(train_test_list, label_list) if i][:data_len]\n",
        "\n",
        "\n",
        "        if not self.is_train:\n",
        "            # self.test_img = [\n",
        "            #     np.array(Image.open(os.path.join(self.root, 'images', test_file)).convert('RGB'))\n",
        "            #     for test_file in test_file_list[:data_len]]\n",
        "\n",
        "            self.test_img = [\n",
        "                imageio.imread(os.path.join(self.root, 'images', test_file))\n",
        "                for test_file in test_file_list[:data_len]]\n",
        "\n",
        "            self.test_label = [x for i, x in zip(train_test_list, label_list) if not i][:data_len]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.is_train:\n",
        "            img, target = self.train_img[index], self.train_label[index]\n",
        "            if len(img.shape) == 2:\n",
        "                img = np.stack([img] * 3, 2)\n",
        "            img = Image.fromarray(img, mode='RGB')\n",
        "            # img = transforms.Resize((600, 600), Image.BILINEAR)(img)\n",
        "            # img = transforms.RandomCrop(INPUT_SIZE)(img)\n",
        "            # img = transforms.RandomHorizontalFlip()(img)\n",
        "            img = transforms.ToTensor()(img)\n",
        "            img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "\n",
        "        else:\n",
        "            img, target = self.test_img[index], self.test_label[index]\n",
        "            if len(img.shape) == 2:\n",
        "                img = np.stack([img] * 3, 2)\n",
        "            img = Image.fromarray(img, mode='RGB')\n",
        "            # img = transforms.Resize((600, 600), Image.BILINEAR)(img)\n",
        "            # img = transforms.CenterCrop(INPUT_SIZE)(img)\n",
        "            img = transforms.ToTensor()(img)\n",
        "            img = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.is_train:\n",
        "            return len(self.train_label)\n",
        "        else:\n",
        "            return len(self.test_label)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     dataset = CUB(root='./CUB_200_2011')\n",
        "#     print(len(dataset.train_img))\n",
        "#     print(len(dataset.train_label))\n",
        "#     for data in dataset:\n",
        "#         print(data[0].size(), data[1])\n",
        "#     dataset = CUB(root='./CUB_200_2011', is_train=False)\n",
        "#     print(len(dataset.test_img))\n",
        "#     print(len(dataset.test_label))\n",
        "#     for data in dataset:\n",
        "#         print(data[0].size(), data[1])\n",
        "# dataset_path = \"/content/mulitmodal\"\n",
        "\n",
        "# dataset = CUB(root=dataset_path)\n",
        "# print(len(dataset.train_img))\n",
        "# print(len(dataset.train_label))\n",
        "# for data in dataset:\n",
        "#    print(data[0].size(), data[1])\n",
        "\n",
        "# dataset = CUB(root=dataset_path, is_train=False)\n",
        "# print(len(dataset.test_img))\n",
        "# print(len(dataset.test_label))\n",
        "# for data in dataset:\n",
        "#    print(data[0].size(), data[1])"
      ],
      "metadata": {
        "id": "zo5uUYtYhWjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet.py"
      ],
      "metadata": {
        "id": "aWUpA83OjNdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        feature1 = x\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = nn.Dropout(p=0.5)(x)\n",
        "        feature2 = x\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x, feature1, feature2\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model"
      ],
      "metadata": {
        "id": "aCdbwE6BjONb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model.py"
      ],
      "metadata": {
        "id": "Uuv8a8uqis8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "# from core import resnet\n",
        "import numpy as np\n",
        "# from core.anchors import generate_default_anchor_maps, hard_nms\n",
        "# from config import CAT_NUM, PROPOSAL_NUM\n",
        "\n",
        "class ProposalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ProposalNet, self).__init__()\n",
        "        self.down1 = nn.Conv2d(2048, 128, 3, 1, 1)\n",
        "        self.down2 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.down3 = nn.Conv2d(128, 128, 3, 2, 1)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.tidy1 = nn.Conv2d(128, 6, 1, 1, 0)\n",
        "        self.tidy2 = nn.Conv2d(128, 6, 1, 1, 0)\n",
        "        self.tidy3 = nn.Conv2d(128, 9, 1, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        d1 = self.ReLU(self.down1(x))\n",
        "        d2 = self.ReLU(self.down2(d1))\n",
        "        d3 = self.ReLU(self.down3(d2))\n",
        "        t1 = self.tidy1(d1).view(batch_size, -1)\n",
        "        t2 = self.tidy2(d2).view(batch_size, -1)\n",
        "        t3 = self.tidy3(d3).view(batch_size, -1)\n",
        "        return torch.cat((t1, t2, t3), dim=1)\n",
        "\n",
        "\n",
        "class attention_net(nn.Module):\n",
        "    def __init__(self, topN=4):\n",
        "        super(attention_net, self).__init__()\n",
        "        self.pretrained_model = resnet50(pretrained=True)\n",
        "        self.pretrained_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.pretrained_model.fc = nn.Linear(512 * 4, 200)\n",
        "        self.proposal_net = ProposalNet()\n",
        "        self.topN = topN\n",
        "        self.concat_net = nn.Linear(2048 * (CAT_NUM + 1), 200)\n",
        "        self.partcls_net = nn.Linear(512 * 4, 200)\n",
        "        _, edge_anchors, _ = generate_default_anchor_maps()\n",
        "        self.pad_side = 224\n",
        "        self.edge_anchors = (edge_anchors + 224).astype(np.int)\n",
        "\n",
        "    def forward(self, x):\n",
        "        resnet_out, rpn_feature, feature = self.pretrained_model(x)\n",
        "        x_pad = F.pad(x, (self.pad_side, self.pad_side, self.pad_side, self.pad_side), mode='constant', value=0)\n",
        "        batch = x.size(0)\n",
        "        # we will reshape rpn to shape: batch * nb_anchor\n",
        "        rpn_score = self.proposal_net(rpn_feature.detach())\n",
        "        all_cdds = [\n",
        "            np.concatenate((x.reshape(-1, 1), self.edge_anchors.copy(), np.arange(0, len(x)).reshape(-1, 1)), axis=1)\n",
        "            for x in rpn_score.data.cpu().numpy()]\n",
        "        top_n_cdds = [hard_nms(x, topn=self.topN, iou_thresh=0.25) for x in all_cdds]\n",
        "        top_n_cdds = np.array(top_n_cdds)\n",
        "        top_n_index = top_n_cdds[:, :, -1].astype(np.int)\n",
        "        top_n_index = torch.from_numpy(top_n_index).cuda()\n",
        "        top_n_prob = torch.gather(rpn_score, dim=1, index=top_n_index)\n",
        "        part_imgs = torch.zeros([batch, self.topN, 3, 224, 224]).cuda()\n",
        "        for i in range(batch):\n",
        "            for j in range(self.topN):\n",
        "                [y0, x0, y1, x1] = top_n_cdds[i][j, 1:5].astype(np.int)\n",
        "                part_imgs[i:i + 1, j] = F.interpolate(x_pad[i:i + 1, :, y0:y1, x0:x1], size=(224, 224), mode='bilinear',\n",
        "                                                      align_corners=True)\n",
        "        part_imgs = part_imgs.view(batch * self.topN, 3, 224, 224)\n",
        "        _, _, part_features = self.pretrained_model(part_imgs.detach())\n",
        "        part_feature = part_features.view(batch, self.topN, -1)\n",
        "        part_feature = part_feature[:, :CAT_NUM, ...].contiguous()\n",
        "        part_feature = part_feature.view(batch, -1)\n",
        "        # concat_logits have the shape: B*200\n",
        "        concat_out = torch.cat([part_feature, feature], dim=1)\n",
        "        concat_logits = self.concat_net(concat_out)\n",
        "        raw_logits = resnet_out\n",
        "        # part_logits have the shape: B*N*200\n",
        "        part_logits = self.partcls_net(part_features).view(batch, self.topN, -1)\n",
        "        return [raw_logits, concat_logits, part_logits, top_n_index, top_n_prob]\n",
        "\n",
        "\n",
        "def list_loss(logits, targets):\n",
        "    temp = F.log_softmax(logits, -1)\n",
        "    loss = [-temp[i][targets[i].item()] for i in range(logits.size(0))]\n",
        "    return torch.stack(loss)\n",
        "\n",
        "\n",
        "def ranking_loss(score, targets, proposal_num=PROPOSAL_NUM):\n",
        "    loss = Variable(torch.zeros(1).cuda())\n",
        "    batch_size = score.size(0)\n",
        "    for i in range(proposal_num):\n",
        "        targets_p = (targets > targets[:, i].unsqueeze(1)).type(torch.cuda.FloatTensor)\n",
        "        pivot = score[:, i].unsqueeze(1)\n",
        "        loss_p = (1 - pivot + score) * targets_p\n",
        "        loss_p = torch.sum(F.relu(loss_p))\n",
        "        loss += loss_p\n",
        "    return loss / batch_size"
      ],
      "metadata": {
        "id": "lzk5GNmmitju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ],
      "metadata": {
        "id": "uN29CpiThX5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GLfbKbogFDr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "from datetime import datetime\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "# from config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir\n",
        "# from core import model, dataset\n",
        "# from core.utils import init_log, progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
        "start_epoch = 1\n",
        "# save_dir = os.path.join(save_dir, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "save_dir = os.path.join(save_dir, datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "\n",
        "if os.path.exists(save_dir):\n",
        "    raise NameError('model dir exists!')\n",
        "os.makedirs(save_dir)\n",
        "logging = init_log(save_dir)\n",
        "_print = logging.info"
      ],
      "metadata": {
        "id": "uPjZwsVZgPsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(save_dir)        # to check the adress of log file"
      ],
      "metadata": {
        "id": "0FAAW7AQ1X5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset\n",
        "# dataset_path = \"/content/CUB_200_2011\"\n",
        "dataset_path = \"/content/mulitmodal\"\n",
        "trainset = CUB(root=dataset_path, is_train=True, data_len=None)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=3, drop_last=False)\n",
        "\n",
        "testset = CUB(root=dataset_path, is_train=False, data_len=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=3, drop_last=False)"
      ],
      "metadata": {
        "id": "lsHBL3mRgR6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06126006-5748-4c53-9914-36070aaae44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d6084f035f80>:41: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  self.train_img = [imageio.imread(os.path.join(self.root, 'images', train_file)) for train_file in\n",
            "<ipython-input-7-d6084f035f80>:52: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  imageio.imread(os.path.join(self.root, 'images', test_file))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "net = attention_net(topN=PROPOSAL_NUM)\n",
        "if resume:\n",
        "    ckpt = torch.load(resume)\n",
        "    net.load_state_dict(ckpt['net_state_dict'])\n",
        "    start_epoch = ckpt['epoch'] + 1\n",
        "creterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TP4NAHrGghgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5297123b-b26c-46e7-f19f-3a72a546bb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-12a142948840>:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_map_shape = output_map_shape.astype(np.int)\n",
            "<ipython-input-9-8be71aa62616>:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.edge_anchors = (edge_anchors + 224).astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define optimizers\n",
        "raw_parameters = list(net.pretrained_model.parameters())\n",
        "part_parameters = list(net.proposal_net.parameters())\n",
        "concat_parameters = list(net.concat_net.parameters())\n",
        "partcls_parameters = list(net.partcls_net.parameters())"
      ],
      "metadata": {
        "id": "7JFzpkKCgnxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_optimizer = torch.optim.SGD(raw_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "concat_optimizer = torch.optim.SGD(concat_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "part_optimizer = torch.optim.SGD(part_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "partcls_optimizer = torch.optim.SGD(partcls_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "schedulers = [MultiStepLR(raw_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "              MultiStepLR(concat_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "              MultiStepLR(part_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "              MultiStepLR(partcls_optimizer, milestones=[60, 100], gamma=0.1)]\n",
        "net = net.cuda()\n",
        "net = DataParallel(net)"
      ],
      "metadata": {
        "id": "Fci9PVT8grs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, 500):\n",
        "    for scheduler in schedulers:\n",
        "        scheduler.step()\n",
        "\n",
        "    # begin training\n",
        "    print('--' * 50)\n",
        "    net.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        img, label = data[0].cuda(), data[1].cuda()\n",
        "        batch_size = img.size(0)\n",
        "        raw_optimizer.zero_grad()\n",
        "        part_optimizer.zero_grad()\n",
        "        concat_optimizer.zero_grad()\n",
        "        partcls_optimizer.zero_grad()\n",
        "\n",
        "        raw_logits, concat_logits, part_logits, _, top_n_prob = net(img)\n",
        "        part_loss = list_loss(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                    label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n",
        "        raw_loss = creterion(raw_logits, label)\n",
        "        concat_loss = creterion(concat_logits, label)\n",
        "        rank_loss = ranking_loss(top_n_prob, part_loss)\n",
        "        partcls_loss = creterion(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                 label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
        "\n",
        "        total_loss = raw_loss + rank_loss + concat_loss + partcls_loss\n",
        "        total_loss.backward()\n",
        "        raw_optimizer.step()\n",
        "        part_optimizer.step()\n",
        "        concat_optimizer.step()\n",
        "        partcls_optimizer.step()\n",
        "        progress_bar(i, len(trainloader), 'train')\n",
        "\n",
        "    if epoch % SAVE_FREQ == 0:\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        total = 0\n",
        "        net.eval()\n",
        "        for i, data in enumerate(trainloader):\n",
        "            with torch.no_grad():\n",
        "                img, label = data[0].cuda(), data[1].cuda()\n",
        "                batch_size = img.size(0)\n",
        "                _, concat_logits, _, _, _ = net(img)\n",
        "                # calculate loss\n",
        "                concat_loss = creterion(concat_logits, label)\n",
        "                # calculate accuracy\n",
        "                _, concat_predict = torch.max(concat_logits, 1)\n",
        "                total += batch_size\n",
        "                train_correct += torch.sum(concat_predict.data == label.data)\n",
        "                train_loss += concat_loss.item() * batch_size\n",
        "                progress_bar(i, len(trainloader), 'eval train set')\n",
        "\n",
        "        train_acc = float(train_correct) / total\n",
        "        train_loss = train_loss / total\n",
        "\n",
        "        print(\n",
        "            'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n",
        "                epoch,\n",
        "                train_loss,\n",
        "                train_acc,\n",
        "                total))\n",
        "\n",
        "\t# evaluate on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(testloader):\n",
        "            with torch.no_grad():\n",
        "                img, label = data[0].cuda(), data[1].cuda()\n",
        "                batch_size = img.size(0)\n",
        "                _, concat_logits, _, _, _ = net(img)\n",
        "                # calculate loss\n",
        "                concat_loss = creterion(concat_logits, label)\n",
        "                # calculate accuracy\n",
        "                _, concat_predict = torch.max(concat_logits, 1)\n",
        "                total += batch_size\n",
        "                test_correct += torch.sum(concat_predict.data == label.data)\n",
        "                test_loss += concat_loss.item() * batch_size\n",
        "                progress_bar(i, len(testloader), 'eval test set')\n",
        "\n",
        "        test_acc = float(test_correct) / total\n",
        "        test_loss = test_loss / total\n",
        "        print(\n",
        "            'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n",
        "                epoch,\n",
        "                test_loss,\n",
        "                test_acc,\n",
        "                total))\n",
        "\n",
        "\t# save model\n",
        "        net_state_dict = net.module.state_dict()\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'test_loss': test_loss,\n",
        "            'test_acc': test_acc,\n",
        "            'net_state_dict': net_state_dict},\n",
        "            os.path.join(save_dir, '%03d.ckpt' % epoch))\n",
        "\n",
        "print('finishing training')"
      ],
      "metadata": {
        "id": "lAtuMMQlguvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ec5fd2-6c81-4446-e40d-6b3fcd0c3a20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-8be71aa62616>:57: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  top_n_index = top_n_cdds[:, :, -1].astype(np.int)\n",
            "<ipython-input-9-8be71aa62616>:63: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  [y0, x0, y1, x1] = top_n_cdds[i][j, 1:5].astype(np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [=======================================>]  Step: 553ms | Tot: 30m25s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 120ms | Tot: 10m32s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:1 - train loss: 0.778 and train acc: 0.652 total sample: 25500\n",
            " [=======================================>]  Step: 196ms | Tot: 49s376ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:1 - test loss: 0.797 and test acc: 0.610 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 482ms | Tot: 30m26s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 117ms | Tot: 10m27s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:2 - train loss: 0.645 and train acc: 0.677 total sample: 25500\n",
            " [=======================================>]  Step: 195ms | Tot: 49s103ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:2 - test loss: 0.737 and test acc: 0.618 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 480ms | Tot: 30m26s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 112ms | Tot: 10m27s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:3 - train loss: 0.662 and train acc: 0.691 total sample: 25500\n",
            " [=======================================>]  Step: 198ms | Tot: 49s58ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:3 - test loss: 0.806 and test acc: 0.620 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 482ms | Tot: 30m23s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 113ms | Tot: 10m26s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:4 - train loss: 0.518 and train acc: 0.737 total sample: 25500\n",
            " [=======================================>]  Step: 195ms | Tot: 48s870ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:4 - test loss: 0.809 and test acc: 0.606 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 478ms | Tot: 30m21s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 116ms | Tot: 10m27s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:5 - train loss: 0.384 and train acc: 0.825 total sample: 25500\n",
            " [=======================================>]  Step: 194ms | Tot: 48s914ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:5 - test loss: 0.976 and test acc: 0.548 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 480ms | Tot: 30m19s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 119ms | Tot: 10m26s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:6 - train loss: 0.512 and train acc: 0.769 total sample: 25500\n",
            " [=======================================>]  Step: 193ms | Tot: 48s825ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:6 - test loss: 1.036 and test acc: 0.544 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            " [=======================================>]  Step: 479ms | Tot: 30m19s | train  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            " [=======================================>]  Step: 123ms | Tot: 10m25s | eval train set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 3188/3188 \n",
            "epoch:7 - train loss: 0.449 and train acc: 0.802 total sample: 25500\n",
            " [=======================================>]  Step: 199ms | Tot: 48s817ms | eval test set\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 250/250 \n",
            "epoch:7 - test loss: 1.003 and test acc: 0.610 total sample: 2000\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test.py"
      ],
      "metadata": {
        "id": "22-x5xhQka64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "# from config import BATCH_SIZE, PROPOSAL_NUM, test_model\n",
        "# from core import model, dataset\n",
        "# from core.utils import progress_bar\n",
        "\n",
        "dataset_path = \"/content/mulitmodal\"\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
        "if not test_model:\n",
        "    raise NameError('please set the test_model file to choose the checkpoint!')\n",
        "# read dataset\n",
        "trainset = CUB(root=dataset_path, is_train=True, data_len=None)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=8, drop_last=False)\n",
        "testset = CUB(root=dataset_path, is_train=False, data_len=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=8, drop_last=False)"
      ],
      "metadata": {
        "id": "onAQKSVMkdUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "net = attention_net(topN=PROPOSAL_NUM)\n",
        "ckpt = torch.load(test_model)\n",
        "net.load_state_dict(ckpt['net_state_dict'])\n",
        "net = net.cuda()\n",
        "net = DataParallel(net)\n",
        "creterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "UDJPK6_04-Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on train set\n",
        "train_loss = 0\n",
        "train_correct = 0\n",
        "total = 0\n",
        "net.eval()\n",
        "\n",
        "for i, data in enumerate(trainloader):\n",
        "    with torch.no_grad():\n",
        "        img, label = data[0].cuda(), data[1].cuda()\n",
        "        batch_size = img.size(0)\n",
        "        _, concat_logits, _, _, _ = net(img)\n",
        "        # calculate loss\n",
        "        concat_loss = creterion(concat_logits, label)\n",
        "        # calculate accuracy\n",
        "        _, concat_predict = torch.max(concat_logits, 1)\n",
        "        total += batch_size\n",
        "        train_correct += torch.sum(concat_predict.data == label.data)\n",
        "        train_loss += concat_loss.item() * batch_size\n",
        "        progress_bar(i, len(trainloader), 'eval on train set')\n",
        "\n",
        "train_acc = float(train_correct) / total\n",
        "train_loss = train_loss / total\n",
        "print('train set loss: {:.3f} and train set acc: {:.3f} total sample: {}'.format(train_loss, train_acc, total))\n",
        "\n",
        "\n",
        "# evaluate on test set\n",
        "test_loss = 0\n",
        "test_correct = 0\n",
        "total = 0\n",
        "for i, data in enumerate(testloader):\n",
        "    with torch.no_grad():\n",
        "        img, label = data[0].cuda(), data[1].cuda()\n",
        "        batch_size = img.size(0)\n",
        "        _, concat_logits, _, _, _ = net(img)\n",
        "        # calculate loss\n",
        "        concat_loss = creterion(concat_logits, label)\n",
        "        # calculate accuracy\n",
        "        _, concat_predict = torch.max(concat_logits, 1)\n",
        "        total += batch_size\n",
        "        test_correct += torch.sum(concat_predict.data == label.data)\n",
        "        test_loss += concat_loss.item() * batch_size\n",
        "        progress_bar(i, len(testloader), 'eval on test set')\n",
        "\n",
        "test_acc = float(test_correct) / total\n",
        "test_loss = test_loss / total\n",
        "print('test set loss: {:.3f} and test set acc: {:.3f} total sample: {}'.format(test_loss, test_acc, total))\n",
        "\n",
        "print('finishing testing')"
      ],
      "metadata": {
        "id": "QaVerhrz4jKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}