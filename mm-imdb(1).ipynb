{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kMuWGf2lyc1A"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/visionCodes/blob/master/mm-imdb(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Dataset(s)/mm-imdb/fused"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZY4W75rjsk4",
        "outputId": "6791b614-62ea-428c-e2a5-0fe951f8bb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dataset(s)/mm-imdb/fused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmF1zNcPTGga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfb4249-0ca8-4a3f-8954-8874e80745a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dxd2pySfCIDJYG7qMtuJre8ph068xc1X\n",
            "To: /content/Dataset(s)/mm-imdb/fused/test.zip\n",
            "100% 2.12G/2.12G [00:26<00:00, 79.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1dxd2pySfCIDJYG7qMtuJre8ph068xc1X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1sYR9EgHkM0oiGRQVlFQCyHO8kMRJ4ibQ"
      ],
      "metadata": {
        "id": "KKm0C_4oTUTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595ecc0e-4d5f-4821-e33f-082e3f8156de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sYR9EgHkM0oiGRQVlFQCyHO8kMRJ4ibQ\n",
            "To: /content/Dataset(s)/mm-imdb/fused/test_label.txt\n",
            "\r  0% 0.00/777k [00:00<?, ?B/s]\r100% 777k/777k [00:00<00:00, 8.16MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1X4cmMYRjxXFomCJ1adMhPNMYtd4WeDHP"
      ],
      "metadata": {
        "id": "JLMZ4FcgyNpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579f4b48-a9e3-44c1-b353-9d843782ee6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1X4cmMYRjxXFomCJ1adMhPNMYtd4WeDHP\n",
            "To: /content/Dataset(s)/mm-imdb/fused/train_label.txt\n",
            "\r  0% 0.00/1.55M [00:00<?, ?B/s]\r100% 1.55M/1.55M [00:00<00:00, 14.6MB/s]\r100% 1.55M/1.55M [00:00<00:00, 14.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1yAeNEPXD3LNxmtSnC09jEg0vEDc1qiaq"
      ],
      "metadata": {
        "id": "sXd76s1XyO5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf9a729-f474-4204-89fe-d89f4893bebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yAeNEPXD3LNxmtSnC09jEg0vEDc1qiaq\n",
            "To: /content/Dataset(s)/mm-imdb/fused/train.zip\n",
            "100% 4.21G/4.21G [00:50<00:00, 83.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test.zip"
      ],
      "metadata": {
        "id": "Q--gX0z1yYPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "A-YkM8B0ywHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "kMuWGf2lyc1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_file, root_dir, transform=None):\n",
        "        self.data_file = data_file\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(data_file, 'r') as f:\n",
        "            self.data = f.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        line = self.data[idx].strip().split('|')\n",
        "        image_path = line[0].strip()\n",
        "        image = Image.open(os.path.join(self.root_dir, image_path))\n",
        "\n",
        "        labels = line[1].strip().split(',')\n",
        "        labels = [label.strip() for label in labels]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, labels\n",
        "\n",
        "# Define data transformations (resize, normalize, etc.)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "2Ozkr7DfTz_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(data_file='/content/test_label.txt', root_dir='/content/test', transform=transform)"
      ],
      "metadata": {
        "id": "oaSIrRIfUB2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "xgbtUmAVUDzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/test_label.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "unique_labels = set()\n",
        "for line in lines:\n",
        "    labels = line.strip().split('|')[1].strip().split(',')\n",
        "    unique_labels.update(labels)\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "print(f\"Number of classes: {num_classes}\")\n"
      ],
      "metadata": {
        "id": "Wky-3_TYUEJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Define your ResNet-101 model\n",
        "model = models.resnet101(pretrained=True)  # You can use a pre-trained model\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, num_classes),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "e76XTKmyVGL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "Yrbpgl2PVYWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}')\n",
        "\n",
        "print('Training finished.')\n",
        "\n",
        "# Now, you can use the trained model for evaluation and prediction\n",
        "# Don't forget to create a DataLoader for your test/validation dataset and evaluate the model's performance.\n"
      ],
      "metadata": {
        "id": "6mFjLf2hVbzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3pqjlyIXMbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset Preparation"
      ],
      "metadata": {
        "id": "VqotBnmCXM6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/Dataset(s)/mm-imdb/fused/train\"\n",
        "labels_file = '/content/Dataset(s)/mm-imdb/fused/train_label.txt'\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        image_file_paths.append(image_path)\n",
        "        genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "O2DdTX5_XNV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_paths"
      ],
      "metadata": {
        "id": "nXDErAZjdJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels"
      ],
      "metadata": {
        "id": "PWOIg0hTdKvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels_set = set()\n",
        "\n",
        "for labels in genre_labels:\n",
        "    unique_labels_set.update(labels)\n",
        "\n",
        "unique_labels = sorted(list(unique_labels_set))"
      ],
      "metadata": {
        "id": "WnWdzeiWXXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels"
      ],
      "metadata": {
        "id": "rB1rz-dwZgxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_labels)"
      ],
      "metadata": {
        "id": "gbg9-ae_zi0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e2cf29-83d7-4708-8130-181a36ce96fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "\n",
        "for labels in genre_labels:\n",
        "    for label in labels:\n",
        "        label_counts[label] += 1"
      ],
      "metadata": {
        "id": "yslKvYyH2tQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts"
      ],
      "metadata": {
        "id": "3DMfkmDS20rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in unique_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "weVX9tVdZhxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels[1]"
      ],
      "metadata": {
        "id": "5BdzoGhlZ1uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7bda95e-af89-4bd6-c191-9fc5509cd556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels[1]"
      ],
      "metadata": {
        "id": "1ozp7IfHZ2-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ae8f92-747b-45cb-f56b-f616c9aa08fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Crime', 'Drama', 'Thriller']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomMultiLabelDataset(Dataset):\n",
        "    def __init__(self, image_file_paths, multi_encoded_labels, transform=None):\n",
        "        self.image_file_paths = image_file_paths\n",
        "        self.multi_encoded_labels = multi_encoded_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_file_paths[idx]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        labels = self.multi_encoded_labels[idx]\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, labels\n",
        "\n",
        "# Define data transformations (resize, normalize, etc.)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "uprw1hgjbHji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset\n",
        "train_dataset = CustomMultiLabelDataset(image_file_paths, multi_hot_labels, transform=transform)"
      ],
      "metadata": {
        "id": "pjHkp2KZblJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "6djdqSdHdylD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5397aa-d196-4eca-fb3e-23a866ddff1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46656"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "XY0b1aLgd1Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Dataset Preparation"
      ],
      "metadata": {
        "id": "W5OWR3LAvXb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "test_image_file_paths = []\n",
        "test_genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/Dataset(s)/mm-imdb/fused/test\"\n",
        "labels_file = '/content/Dataset(s)/mm-imdb/fused/test_label.txt'\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        test_image_file_paths.append(image_path)\n",
        "        test_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "KgZ0M9ixvX7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_labels_set = set()\n",
        "\n",
        "# for labels in test_genre_labels:\n",
        "#     unique_labels_set.update(labels)\n",
        "\n",
        "# unique_labels = sorted(list(unique_labels_set))"
      ],
      "metadata": {
        "id": "NL2o6TmXz2mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_labels"
      ],
      "metadata": {
        "id": "ah5w4E1lz-V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_labels)"
      ],
      "metadata": {
        "id": "UIHFyIP-z7P8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3d1864-6fa1-4430-83bc-2d17f6bd30f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_multi_hot_labels = []\n",
        "\n",
        "for labels in test_genre_labels:\n",
        "    test_multi_hot = [1 if label in labels else 0 for label in unique_labels]\n",
        "    test_multi_hot_labels.append(test_multi_hot)"
      ],
      "metadata": {
        "id": "PFyQCaOQveK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomMultiLabelDataset(test_image_file_paths, test_multi_hot_labels, transform=transform)"
      ],
      "metadata": {
        "id": "BculxAgbwCed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "id": "dRs9JPiR1L6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec7ca6e-322e-4b56-ba0a-017a821682fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23397"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQrQPBjm1NgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "T73kFItave8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "qmjc3h-Xb3pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model = models.resnet101(pretrained=True)  # You can use a pre-trained model\n",
        "\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Linear(model.fc.in_features, 512),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(512, len(unique_labels)),\n",
        "#     nn.Sigmoid()\n",
        "# )\n",
        "\n",
        "model = models.resnet101(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(unique_labels))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "nzkSDHpbcBvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 30"
      ],
      "metadata": {
        "id": "W3xyf2mIcUp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    if epoch > 15:\n",
        "      save_dir = \"/content/Model/Models-Train-21/\"\n",
        "      os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "      model_name = str(epoch) + \"_model.pth\"\n",
        "      save_path = os.path.join(save_dir, model_name)  # Specify the complete path to the model file\n",
        "      torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # loss = criterion(outputs, labels.float())\n",
        "\n",
        "            # Apply a threshold (e.g., 0.5) to convert logits to binary predictions\n",
        "            predictions.extend((outputs > 0.5).int().cpu().numpy())\n",
        "            true_labels.extend(labels.int().cpu().numpy())\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(classification_report(true_labels, predictions))"
      ],
      "metadata": {
        "id": "ZRds1BV-chaz",
        "outputId": "0312d2db-105f-49d4-f082-47a4f146454f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 0.24515408999063024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.09082360986451254\n",
            "Precision: 0.27835498477572496\n",
            "Recall: 0.04454686297087706\n",
            "F1-Score: 0.05403379672160902\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.01      0.02      3132\n",
            "           1       0.67      0.01      0.02      2463\n",
            "           2       0.76      0.03      0.06       918\n",
            "           3       0.00      0.00      0.00      1233\n",
            "           4       0.66      0.15      0.24      7833\n",
            "           5       0.62      0.01      0.01      3489\n",
            "           6       0.00      0.00      0.00      1887\n",
            "           7       0.63      0.75      0.68     12426\n",
            "           8       0.74      0.03      0.05      1554\n",
            "           9       0.00      0.00      0.00      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.00      0.00      0.00      1035\n",
            "          12       0.47      0.01      0.01      2475\n",
            "          13       0.00      0.00      0.00       933\n",
            "          14       0.00      0.00      0.00       759\n",
            "          15       0.32      0.00      0.01      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.53      0.02      0.03      4770\n",
            "          19       0.63      0.11      0.19      1758\n",
            "          20       0.00      0.00      0.00       426\n",
            "          21       0.00      0.00      0.00       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.69      0.04      0.07      4701\n",
            "          24       0.00      0.00      0.00      1203\n",
            "          25       0.00      0.00      0.00       630\n",
            "\n",
            "   micro avg       0.63      0.19      0.29     58167\n",
            "   macro avg       0.28      0.04      0.05     58167\n",
            "weighted avg       0.50      0.19      0.20     58167\n",
            " samples avg       0.44      0.24      0.29     58167\n",
            "\n",
            "Epoch 2/30, Loss: 0.21398276726323065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.08253194854041117\n",
            "Precision: 0.39690797472178324\n",
            "Recall: 0.10114525517510352\n",
            "F1-Score: 0.14737595398075803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.11      0.18      3132\n",
            "           1       0.65      0.14      0.24      2463\n",
            "           2       0.71      0.12      0.21       918\n",
            "           3       0.00      0.00      0.00      1233\n",
            "           4       0.80      0.14      0.23      7833\n",
            "           5       0.71      0.21      0.33      3489\n",
            "           6       0.73      0.53      0.61      1887\n",
            "           7       0.85      0.31      0.45     12426\n",
            "           8       0.87      0.06      0.11      1554\n",
            "           9       0.64      0.01      0.02      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.00      0.00      0.00      1035\n",
            "          12       0.77      0.20      0.32      2475\n",
            "          13       0.00      0.00      0.00       933\n",
            "          14       0.00      0.00      0.00       759\n",
            "          15       0.35      0.02      0.03      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.66      0.02      0.03      4770\n",
            "          19       0.55      0.32      0.40      1758\n",
            "          20       0.00      0.00      0.00       426\n",
            "          21       0.00      0.00      0.00       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.61      0.28      0.38      4701\n",
            "          24       0.77      0.17      0.28      1203\n",
            "          25       0.00      0.00      0.00       630\n",
            "\n",
            "   micro avg       0.74      0.18      0.28     58167\n",
            "   macro avg       0.40      0.10      0.15     58167\n",
            "weighted avg       0.65      0.18      0.26     58167\n",
            " samples avg       0.36      0.21      0.25     58167\n",
            "\n",
            "Epoch 3/30, Loss: 0.19327441958610903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1173654742060948\n",
            "Precision: 0.49723130716092234\n",
            "Recall: 0.12309047369755517\n",
            "F1-Score: 0.17527298358621315\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.23      0.34      3132\n",
            "           1       0.72      0.10      0.17      2463\n",
            "           2       0.72      0.08      0.14       918\n",
            "           3       0.00      0.00      0.00      1233\n",
            "           4       0.85      0.11      0.20      7833\n",
            "           5       0.75      0.23      0.36      3489\n",
            "           6       0.74      0.51      0.60      1887\n",
            "           7       0.76      0.57      0.65     12426\n",
            "           8       0.80      0.13      0.23      1554\n",
            "           9       0.68      0.03      0.05      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.53      0.01      0.02      1035\n",
            "          12       0.77      0.41      0.54      2475\n",
            "          13       0.56      0.04      0.08       933\n",
            "          14       0.00      0.00      0.00       759\n",
            "          15       0.75      0.01      0.03      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.75      0.03      0.06      4770\n",
            "          19       0.85      0.17      0.28      1758\n",
            "          20       0.00      0.00      0.00       426\n",
            "          21       0.00      0.00      0.00       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.69      0.25      0.37      4701\n",
            "          24       0.78      0.23      0.36      1203\n",
            "          25       0.61      0.05      0.10       630\n",
            "\n",
            "   micro avg       0.75      0.24      0.37     58167\n",
            "   macro avg       0.50      0.12      0.18     58167\n",
            "weighted avg       0.70      0.24      0.32     58167\n",
            " samples avg       0.50      0.29      0.34     58167\n",
            "\n",
            "Epoch 4/30, Loss: 0.18271356184337037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14882249861093302\n",
            "Precision: 0.5684916605554333\n",
            "Recall: 0.18520148967474867\n",
            "F1-Score: 0.24129202140147177\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.22      0.34      3132\n",
            "           1       0.79      0.10      0.18      2463\n",
            "           2       0.89      0.06      0.12       918\n",
            "           3       0.50      0.00      0.00      1233\n",
            "           4       0.79      0.27      0.40      7833\n",
            "           5       0.78      0.25      0.38      3489\n",
            "           6       0.83      0.50      0.62      1887\n",
            "           7       0.72      0.77      0.74     12426\n",
            "           8       0.97      0.10      0.19      1554\n",
            "           9       0.83      0.08      0.15      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.32      0.06      0.09      1035\n",
            "          12       0.77      0.47      0.58      2475\n",
            "          13       0.71      0.11      0.18       933\n",
            "          14       0.00      0.00      0.00       759\n",
            "          15       0.70      0.03      0.07      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.69      0.13      0.22      4770\n",
            "          19       0.78      0.38      0.51      1758\n",
            "          20       0.00      0.00      0.00       426\n",
            "          21       0.90      0.06      0.12       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.66      0.38      0.48      4701\n",
            "          24       0.55      0.67      0.60      1203\n",
            "          25       0.88      0.17      0.29       630\n",
            "\n",
            "   micro avg       0.72      0.35      0.47     58167\n",
            "   macro avg       0.57      0.19      0.24     58167\n",
            "weighted avg       0.72      0.35      0.41     58167\n",
            " samples avg       0.63      0.40      0.46     58167\n",
            "\n",
            "Epoch 5/30, Loss: 0.17375820007466486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14801042868743855\n",
            "Precision: 0.5546820514289457\n",
            "Recall: 0.23442553427520738\n",
            "F1-Score: 0.30343587605700123\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.34      0.46      3132\n",
            "           1       0.67      0.24      0.36      2463\n",
            "           2       0.57      0.41      0.48       918\n",
            "           3       0.50      0.00      0.01      1233\n",
            "           4       0.68      0.55      0.61      7833\n",
            "           5       0.76      0.24      0.37      3489\n",
            "           6       0.79      0.63      0.70      1887\n",
            "           7       0.85      0.43      0.57     12426\n",
            "           8       0.56      0.45      0.50      1554\n",
            "           9       0.65      0.21      0.31      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.52      0.02      0.03      1035\n",
            "          12       0.71      0.58      0.64      2475\n",
            "          13       0.61      0.32      0.42       933\n",
            "          14       0.38      0.03      0.06       759\n",
            "          15       0.56      0.05      0.10      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.69      0.17      0.28      4770\n",
            "          19       0.75      0.47      0.58      1758\n",
            "          20       0.27      0.02      0.03       426\n",
            "          21       0.67      0.27      0.39       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.71      0.28      0.40      4701\n",
            "          24       0.90      0.21      0.34      1203\n",
            "          25       0.95      0.16      0.27       630\n",
            "\n",
            "   micro avg       0.73      0.35      0.47     58167\n",
            "   macro avg       0.55      0.23      0.30     58167\n",
            "weighted avg       0.71      0.35      0.44     58167\n",
            " samples avg       0.60      0.40      0.45     58167\n",
            "\n",
            "Epoch 6/30, Loss: 0.1675571162095204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1464290293627388\n",
            "Precision: 0.6058441950180398\n",
            "Recall: 0.22641186129294016\n",
            "F1-Score: 0.28890994695277816\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.04      0.08      3132\n",
            "           1       0.76      0.17      0.28      2463\n",
            "           2       0.73      0.23      0.35       918\n",
            "           3       0.50      0.00      0.01      1233\n",
            "           4       0.68      0.55      0.61      7833\n",
            "           5       0.82      0.19      0.30      3489\n",
            "           6       0.79      0.51      0.62      1887\n",
            "           7       0.74      0.72      0.73     12426\n",
            "           8       0.70      0.35      0.47      1554\n",
            "           9       0.64      0.21      0.32      1755\n",
            "          10       0.80      0.03      0.05       306\n",
            "          11       0.60      0.01      0.02      1035\n",
            "          12       0.90      0.24      0.38      2475\n",
            "          13       0.58      0.41      0.48       933\n",
            "          14       0.28      0.21      0.24       759\n",
            "          15       0.58      0.09      0.15      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.49      0.53      0.51      4770\n",
            "          19       0.91      0.11      0.20      1758\n",
            "          20       0.35      0.01      0.03       426\n",
            "          21       0.70      0.30      0.42       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.80      0.10      0.17      4701\n",
            "          24       0.81      0.35      0.49      1203\n",
            "          25       0.71      0.51      0.60       630\n",
            "\n",
            "   micro avg       0.68      0.38      0.49     58167\n",
            "   macro avg       0.61      0.23      0.29     58167\n",
            "weighted avg       0.71      0.38      0.44     58167\n",
            " samples avg       0.61      0.44      0.47     58167\n",
            "\n",
            "Epoch 7/30, Loss: 0.16099416496761051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.16493567551395477\n",
            "Precision: 0.5971984271392755\n",
            "Recall: 0.24657397081904148\n",
            "F1-Score: 0.3272479240561247\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.25      0.37      3132\n",
            "           1       0.70      0.22      0.33      2463\n",
            "           2       0.73      0.28      0.40       918\n",
            "           3       0.54      0.02      0.03      1233\n",
            "           4       0.72      0.50      0.59      7833\n",
            "           5       0.68      0.46      0.55      3489\n",
            "           6       0.87      0.41      0.55      1887\n",
            "           7       0.76      0.69      0.72     12426\n",
            "           8       0.75      0.34      0.47      1554\n",
            "           9       0.89      0.05      0.10      1755\n",
            "          10       0.29      0.06      0.09       306\n",
            "          11       0.59      0.06      0.11      1035\n",
            "          12       0.80      0.44      0.57      2475\n",
            "          13       0.63      0.27      0.38       933\n",
            "          14       0.41      0.06      0.10       759\n",
            "          15       0.55      0.10      0.17      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.66      0.27      0.38      4770\n",
            "          19       0.91      0.25      0.39      1758\n",
            "          20       0.41      0.05      0.08       426\n",
            "          21       0.69      0.37      0.48       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.68      0.40      0.50      4701\n",
            "          24       0.78      0.44      0.56      1203\n",
            "          25       0.79      0.44      0.57       630\n",
            "\n",
            "   micro avg       0.73      0.40      0.52     58167\n",
            "   macro avg       0.60      0.25      0.33     58167\n",
            "weighted avg       0.72      0.40      0.49     58167\n",
            " samples avg       0.66      0.46      0.51     58167\n",
            "\n",
            "Epoch 8/30, Loss: 0.15368517913404642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.15151515151515152\n",
            "Precision: 0.5770984058620076\n",
            "Recall: 0.23623344685090597\n",
            "F1-Score: 0.2900839508294345\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.28      0.41      3132\n",
            "           1       0.70      0.19      0.30      2463\n",
            "           2       0.80      0.15      0.26       918\n",
            "           3       0.50      0.00      0.01      1233\n",
            "           4       0.75      0.41      0.53      7833\n",
            "           5       0.72      0.36      0.48      3489\n",
            "           6       0.39      0.91      0.54      1887\n",
            "           7       0.75      0.60      0.67     12426\n",
            "           8       0.83      0.17      0.28      1554\n",
            "           9       0.71      0.17      0.28      1755\n",
            "          10       0.00      0.00      0.00       306\n",
            "          11       0.49      0.02      0.04      1035\n",
            "          12       0.81      0.46      0.59      2475\n",
            "          13       0.52      0.51      0.52       933\n",
            "          14       0.50      0.01      0.03       759\n",
            "          15       0.65      0.09      0.15      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.73      0.13      0.22      4770\n",
            "          19       0.68      0.52      0.59      1758\n",
            "          20       0.59      0.03      0.06       426\n",
            "          21       0.66      0.35      0.45       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.70      0.22      0.34      4701\n",
            "          24       0.80      0.36      0.50      1203\n",
            "          25       0.97      0.18      0.30       630\n",
            "\n",
            "   micro avg       0.69      0.36      0.47     58167\n",
            "   macro avg       0.58      0.24      0.29     58167\n",
            "weighted avg       0.71      0.36      0.44     58167\n",
            " samples avg       0.62      0.42      0.46     58167\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30, Loss: 0.1454128679015836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1648929349916656\n",
            "Precision: 0.5986463633582425\n",
            "Recall: 0.2616637305374706\n",
            "F1-Score: 0.3428590637689223\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.35      0.46      3132\n",
            "           1       0.69      0.20      0.31      2463\n",
            "           2       0.77      0.21      0.33       918\n",
            "           3       0.61      0.03      0.06      1233\n",
            "           4       0.74      0.46      0.57      7833\n",
            "           5       0.64      0.47      0.54      3489\n",
            "           6       0.73      0.70      0.71      1887\n",
            "           7       0.77      0.66      0.71     12426\n",
            "           8       0.77      0.29      0.42      1554\n",
            "           9       0.75      0.16      0.26      1755\n",
            "          10       0.26      0.08      0.13       306\n",
            "          11       0.53      0.10      0.17      1035\n",
            "          12       0.80      0.39      0.53      2475\n",
            "          13       0.67      0.26      0.37       933\n",
            "          14       0.43      0.06      0.10       759\n",
            "          15       0.47      0.22      0.30      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.62      0.32      0.42      4770\n",
            "          19       0.82      0.38      0.52      1758\n",
            "          20       0.75      0.03      0.05       426\n",
            "          21       0.75      0.32      0.45       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.72      0.28      0.41      4701\n",
            "          24       0.76      0.46      0.57      1203\n",
            "          25       0.82      0.39      0.53       630\n",
            "\n",
            "   micro avg       0.72      0.41      0.52     58167\n",
            "   macro avg       0.60      0.26      0.34     58167\n",
            "weighted avg       0.71      0.41      0.50     58167\n",
            " samples avg       0.67      0.46      0.51     58167\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30, Loss: 0.13585536540147372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.16651707483865452\n",
            "Precision: 0.5685830054900438\n",
            "Recall: 0.275878271125657\n",
            "F1-Score: 0.3554971033262321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.33      0.45      3132\n",
            "           1       0.64      0.26      0.37      2463\n",
            "           2       0.71      0.20      0.32       918\n",
            "           3       0.38      0.16      0.22      1233\n",
            "           4       0.75      0.46      0.57      7833\n",
            "           5       0.74      0.34      0.46      3489\n",
            "           6       0.79      0.55      0.65      1887\n",
            "           7       0.73      0.75      0.74     12426\n",
            "           8       0.78      0.24      0.36      1554\n",
            "           9       0.70      0.18      0.29      1755\n",
            "          10       0.37      0.05      0.09       306\n",
            "          11       0.48      0.12      0.20      1035\n",
            "          12       0.80      0.44      0.57      2475\n",
            "          13       0.62      0.35      0.45       933\n",
            "          14       0.42      0.09      0.15       759\n",
            "          15       0.51      0.22      0.31      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.59      0.35      0.44      4770\n",
            "          19       0.76      0.49      0.59      1758\n",
            "          20       0.38      0.01      0.03       426\n",
            "          21       0.73      0.33      0.45       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.73      0.24      0.36      4701\n",
            "          24       0.79      0.42      0.55      1203\n",
            "          25       0.67      0.59      0.63       630\n",
            "\n",
            "   micro avg       0.71      0.42      0.53     58167\n",
            "   macro avg       0.57      0.28      0.36     58167\n",
            "weighted avg       0.69      0.42      0.50     58167\n",
            " samples avg       0.68      0.48      0.52     58167\n",
            "\n",
            "Epoch 11/30, Loss: 0.12453621036190392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14702739667478737\n",
            "Precision: 0.5504312822684027\n",
            "Recall: 0.30142377191052194\n",
            "F1-Score: 0.355999251023204\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.68      0.56      3132\n",
            "           1       0.60      0.33      0.42      2463\n",
            "           2       0.74      0.27      0.39       918\n",
            "           3       0.49      0.03      0.06      1233\n",
            "           4       0.73      0.48      0.58      7833\n",
            "           5       0.66      0.44      0.52      3489\n",
            "           6       0.69      0.70      0.69      1887\n",
            "           7       0.79      0.54      0.65     12426\n",
            "           8       0.80      0.17      0.28      1554\n",
            "           9       0.64      0.22      0.33      1755\n",
            "          10       0.36      0.06      0.10       306\n",
            "          11       0.42      0.18      0.25      1035\n",
            "          12       0.69      0.57      0.62      2475\n",
            "          13       0.71      0.15      0.24       933\n",
            "          14       0.54      0.03      0.06       759\n",
            "          15       0.47      0.21      0.29      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.65      0.21      0.32      4770\n",
            "          19       0.67      0.55      0.60      1758\n",
            "          20       0.52      0.04      0.07       426\n",
            "          21       0.72      0.38      0.50       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.55      0.61      0.57      4701\n",
            "          24       0.63      0.60      0.62      1203\n",
            "          25       0.79      0.40      0.53       630\n",
            "\n",
            "   micro avg       0.66      0.44      0.52     58167\n",
            "   macro avg       0.55      0.30      0.36     58167\n",
            "weighted avg       0.66      0.44      0.50     58167\n",
            " samples avg       0.63      0.48      0.51     58167\n",
            "\n",
            "Epoch 12/30, Loss: 0.11118503543963484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.15142967047057315\n",
            "Precision: 0.545240767366447\n",
            "Recall: 0.2871466136829862\n",
            "F1-Score: 0.3532425563626954\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.44      0.51      3132\n",
            "           1       0.53      0.39      0.45      2463\n",
            "           2       0.68      0.21      0.32       918\n",
            "           3       0.33      0.16      0.22      1233\n",
            "           4       0.82      0.22      0.34      7833\n",
            "           5       0.65      0.46      0.54      3489\n",
            "           6       0.75      0.61      0.67      1887\n",
            "           7       0.68      0.83      0.75     12426\n",
            "           8       0.62      0.39      0.48      1554\n",
            "           9       0.54      0.27      0.36      1755\n",
            "          10       0.46      0.04      0.08       306\n",
            "          11       0.34      0.21      0.26      1035\n",
            "          12       0.78      0.47      0.59      2475\n",
            "          13       0.62      0.28      0.38       933\n",
            "          14       0.56      0.04      0.07       759\n",
            "          15       0.52      0.12      0.19      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.68      0.13      0.22      4770\n",
            "          19       0.82      0.36      0.50      1758\n",
            "          20       0.48      0.07      0.13       426\n",
            "          21       0.58      0.44      0.50       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.66      0.33      0.44      4701\n",
            "          24       0.77      0.48      0.59      1203\n",
            "          25       0.70      0.50      0.58       630\n",
            "\n",
            "   micro avg       0.66      0.42      0.52     58167\n",
            "   macro avg       0.55      0.29      0.35     58167\n",
            "weighted avg       0.67      0.42      0.48     58167\n",
            " samples avg       0.66      0.47      0.51     58167\n",
            "\n",
            "Epoch 13/30, Loss: 0.09741177467887376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14698465615249817\n",
            "Precision: 0.5183036344272121\n",
            "Recall: 0.31515117674406284\n",
            "F1-Score: 0.37501427585902536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.32      0.43      3132\n",
            "           1       0.58      0.24      0.34      2463\n",
            "           2       0.59      0.41      0.48       918\n",
            "           3       0.29      0.20      0.24      1233\n",
            "           4       0.72      0.45      0.56      7833\n",
            "           5       0.66      0.41      0.51      3489\n",
            "           6       0.60      0.79      0.68      1887\n",
            "           7       0.70      0.76      0.73     12426\n",
            "           8       0.68      0.35      0.46      1554\n",
            "           9       0.56      0.21      0.31      1755\n",
            "          10       0.45      0.09      0.15       306\n",
            "          11       0.36      0.21      0.27      1035\n",
            "          12       0.83      0.37      0.51      2475\n",
            "          13       0.60      0.31      0.41       933\n",
            "          14       0.43      0.05      0.10       759\n",
            "          15       0.46      0.16      0.24      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.48      0.52      0.50      4770\n",
            "          19       0.75      0.41      0.53      1758\n",
            "          20       0.38      0.11      0.17       426\n",
            "          21       0.64      0.41      0.50       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.65      0.36      0.47      4701\n",
            "          24       0.63      0.58      0.61      1203\n",
            "          25       0.75      0.46      0.57       630\n",
            "\n",
            "   micro avg       0.64      0.46      0.54     58167\n",
            "   macro avg       0.52      0.32      0.38     58167\n",
            "weighted avg       0.64      0.46      0.52     58167\n",
            " samples avg       0.63      0.52      0.53     58167\n",
            "\n",
            "Epoch 14/30, Loss: 0.08377045293597936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.13711159550369706\n",
            "Precision: 0.5189022374889896\n",
            "Recall: 0.3039453606122126\n",
            "F1-Score: 0.35578390909220486\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.53      3132\n",
            "           1       0.50      0.33      0.40      2463\n",
            "           2       0.61      0.33      0.43       918\n",
            "           3       0.38      0.09      0.14      1233\n",
            "           4       0.72      0.47      0.57      7833\n",
            "           5       0.60      0.47      0.53      3489\n",
            "           6       0.62      0.77      0.69      1887\n",
            "           7       0.78      0.52      0.63     12426\n",
            "           8       0.66      0.24      0.35      1554\n",
            "           9       0.51      0.29      0.37      1755\n",
            "          10       0.48      0.04      0.07       306\n",
            "          11       0.46      0.13      0.20      1035\n",
            "          12       0.66      0.61      0.63      2475\n",
            "          13       0.59      0.29      0.39       933\n",
            "          14       0.53      0.01      0.02       759\n",
            "          15       0.35      0.32      0.34      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.67      0.12      0.20      4770\n",
            "          19       0.56      0.59      0.57      1758\n",
            "          20       0.42      0.10      0.17       426\n",
            "          21       0.76      0.25      0.38       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.56      0.53      0.54      4701\n",
            "          24       0.72      0.51      0.60      1203\n",
            "          25       0.80      0.38      0.52       630\n",
            "\n",
            "   micro avg       0.64      0.42      0.51     58167\n",
            "   macro avg       0.52      0.30      0.36     58167\n",
            "weighted avg       0.64      0.42      0.49     58167\n",
            " samples avg       0.62      0.47      0.50     58167\n",
            "\n",
            "Epoch 15/30, Loss: 0.07126946946598375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14104372355430184\n",
            "Precision: 0.5000923741566091\n",
            "Recall: 0.32579495218636867\n",
            "F1-Score: 0.38191350243835853\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.42      0.49      3132\n",
            "           1       0.49      0.40      0.44      2463\n",
            "           2       0.67      0.29      0.41       918\n",
            "           3       0.35      0.08      0.14      1233\n",
            "           4       0.63      0.58      0.60      7833\n",
            "           5       0.57      0.55      0.56      3489\n",
            "           6       0.72      0.63      0.67      1887\n",
            "           7       0.74      0.64      0.69     12426\n",
            "           8       0.59      0.34      0.44      1554\n",
            "           9       0.55      0.28      0.37      1755\n",
            "          10       0.30      0.20      0.24       306\n",
            "          11       0.46      0.08      0.14      1035\n",
            "          12       0.68      0.56      0.61      2475\n",
            "          13       0.56      0.35      0.43       933\n",
            "          14       0.34      0.15      0.21       759\n",
            "          15       0.32      0.28      0.30      1851\n",
            "          16       0.20      0.02      0.03        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.51      0.39      0.44      4770\n",
            "          19       0.64      0.49      0.55      1758\n",
            "          20       0.29      0.10      0.15       426\n",
            "          21       0.70      0.28      0.40       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.55      0.50      0.53      4701\n",
            "          24       0.79      0.36      0.49      1203\n",
            "          25       0.74      0.49      0.59       630\n",
            "\n",
            "   micro avg       0.62      0.48      0.54     58167\n",
            "   macro avg       0.50      0.33      0.38     58167\n",
            "weighted avg       0.61      0.48      0.53     58167\n",
            " samples avg       0.62      0.53      0.53     58167\n",
            "\n",
            "Epoch 16/30, Loss: 0.05906036358444207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14006069154165063\n",
            "Precision: 0.4859624693823006\n",
            "Recall: 0.3163622777495811\n",
            "F1-Score: 0.3643810575019476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.45      0.50      3132\n",
            "           1       0.56      0.27      0.36      2463\n",
            "           2       0.63      0.30      0.41       918\n",
            "           3       0.41      0.04      0.07      1233\n",
            "           4       0.71      0.45      0.55      7833\n",
            "           5       0.62      0.44      0.51      3489\n",
            "           6       0.70      0.66      0.68      1887\n",
            "           7       0.74      0.60      0.66     12426\n",
            "           8       0.54      0.41      0.47      1554\n",
            "           9       0.41      0.35      0.38      1755\n",
            "          10       0.29      0.13      0.18       306\n",
            "          11       0.50      0.06      0.11      1035\n",
            "          12       0.55      0.72      0.62      2475\n",
            "          13       0.55      0.39      0.45       933\n",
            "          14       0.44      0.08      0.14       759\n",
            "          15       0.47      0.13      0.21      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.60      0.22      0.32      4770\n",
            "          19       0.61      0.55      0.58      1758\n",
            "          20       0.27      0.08      0.12       426\n",
            "          21       0.56      0.49      0.53       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.55      0.45      0.49      4701\n",
            "          24       0.67      0.49      0.57      1203\n",
            "          25       0.68      0.47      0.56       630\n",
            "\n",
            "   micro avg       0.63      0.43      0.51     58167\n",
            "   macro avg       0.49      0.32      0.36     58167\n",
            "weighted avg       0.62      0.43      0.50     58167\n",
            " samples avg       0.62      0.48      0.50     58167\n",
            "\n",
            "Epoch 17/30, Loss: 0.050184500746081474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.12108389964525366\n",
            "Precision: 0.48079177752183794\n",
            "Recall: 0.359024794678915\n",
            "F1-Score: 0.38948910241257095\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.48      0.51      3132\n",
            "           1       0.48      0.40      0.44      2463\n",
            "           2       0.44      0.51      0.47       918\n",
            "           3       0.29      0.09      0.14      1233\n",
            "           4       0.63      0.58      0.60      7833\n",
            "           5       0.50      0.64      0.56      3489\n",
            "           6       0.73      0.62      0.67      1887\n",
            "           7       0.69      0.78      0.73     12426\n",
            "           8       0.46      0.48      0.47      1554\n",
            "           9       0.44      0.32      0.37      1755\n",
            "          10       0.39      0.04      0.08       306\n",
            "          11       0.37      0.19      0.25      1035\n",
            "          12       0.73      0.50      0.59      2475\n",
            "          13       0.43      0.48      0.45       933\n",
            "          14       0.39      0.11      0.17       759\n",
            "          15       0.35      0.29      0.32      1851\n",
            "          16       0.67      0.04      0.07        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.47      0.41      0.43      4770\n",
            "          19       0.70      0.45      0.54      1758\n",
            "          20       0.26      0.11      0.16       426\n",
            "          21       0.60      0.35      0.44       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.56      0.48      0.51      4701\n",
            "          24       0.75      0.42      0.54      1203\n",
            "          25       0.62      0.58      0.60       630\n",
            "\n",
            "   micro avg       0.58      0.52      0.55     58167\n",
            "   macro avg       0.48      0.36      0.39     58167\n",
            "weighted avg       0.57      0.52      0.54     58167\n",
            " samples avg       0.61      0.58      0.55     58167\n",
            "\n",
            "Epoch 18/30, Loss: 0.042163286752876186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.13326494849767065\n",
            "Precision: 0.5039830869578553\n",
            "Recall: 0.32424966703243874\n",
            "F1-Score: 0.37664151027477116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.55      0.52      3132\n",
            "           1       0.50      0.37      0.43      2463\n",
            "           2       0.59      0.37      0.46       918\n",
            "           3       0.30      0.12      0.17      1233\n",
            "           4       0.66      0.53      0.59      7833\n",
            "           5       0.57      0.55      0.56      3489\n",
            "           6       0.70      0.67      0.68      1887\n",
            "           7       0.70      0.74      0.72     12426\n",
            "           8       0.63      0.28      0.39      1554\n",
            "           9       0.49      0.23      0.31      1755\n",
            "          10       0.36      0.11      0.17       306\n",
            "          11       0.29      0.32      0.30      1035\n",
            "          12       0.75      0.42      0.53      2475\n",
            "          13       0.66      0.24      0.35       933\n",
            "          14       0.45      0.07      0.12       759\n",
            "          15       0.44      0.16      0.24      1851\n",
            "          16       0.40      0.07      0.12        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.58      0.19      0.28      4770\n",
            "          19       0.70      0.47      0.56      1758\n",
            "          20       0.26      0.16      0.19       426\n",
            "          21       0.69      0.27      0.39       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.57      0.47      0.51      4701\n",
            "          24       0.64      0.57      0.60      1203\n",
            "          25       0.68      0.52      0.59       630\n",
            "\n",
            "   micro avg       0.61      0.47      0.54     58167\n",
            "   macro avg       0.50      0.32      0.38     58167\n",
            "weighted avg       0.60      0.47      0.51     58167\n",
            " samples avg       0.63      0.52      0.53     58167\n",
            "\n",
            "Epoch 19/30, Loss: 0.03677137355308658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.13600034192417831\n",
            "Precision: 0.48276512073860456\n",
            "Recall: 0.32669855392290625\n",
            "F1-Score: 0.3803852293829708\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.48      0.51      3132\n",
            "           1       0.51      0.35      0.42      2463\n",
            "           2       0.63      0.29      0.40       918\n",
            "           3       0.34      0.10      0.15      1233\n",
            "           4       0.68      0.49      0.57      7833\n",
            "           5       0.63      0.45      0.52      3489\n",
            "           6       0.79      0.51      0.62      1887\n",
            "           7       0.69      0.76      0.73     12426\n",
            "           8       0.45      0.47      0.46      1554\n",
            "           9       0.48      0.30      0.37      1755\n",
            "          10       0.37      0.11      0.17       306\n",
            "          11       0.44      0.14      0.21      1035\n",
            "          12       0.73      0.52      0.61      2475\n",
            "          13       0.55      0.34      0.42       933\n",
            "          14       0.32      0.15      0.20       759\n",
            "          15       0.38      0.30      0.33      1851\n",
            "          16       0.00      0.00      0.00        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.52      0.27      0.35      4770\n",
            "          19       0.62      0.54      0.58      1758\n",
            "          20       0.33      0.10      0.15       426\n",
            "          21       0.57      0.49      0.53       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.62      0.35      0.44      4701\n",
            "          24       0.70      0.48      0.57      1203\n",
            "          25       0.66      0.51      0.57       630\n",
            "\n",
            "   micro avg       0.62      0.47      0.54     58167\n",
            "   macro avg       0.48      0.33      0.38     58167\n",
            "weighted avg       0.60      0.47      0.52     58167\n",
            " samples avg       0.63      0.52      0.53     58167\n",
            "\n",
            "Epoch 20/30, Loss: 0.03218264673262916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1243749198615207\n",
            "Precision: 0.5085178679592662\n",
            "Recall: 0.3205503711553183\n",
            "F1-Score: 0.3685529498980363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.28      0.40      3132\n",
            "           1       0.56      0.30      0.39      2463\n",
            "           2       0.65      0.23      0.34       918\n",
            "           3       0.33      0.20      0.25      1233\n",
            "           4       0.71      0.41      0.52      7833\n",
            "           5       0.60      0.48      0.53      3489\n",
            "           6       0.75      0.53      0.62      1887\n",
            "           7       0.69      0.74      0.71     12426\n",
            "           8       0.72      0.15      0.25      1554\n",
            "           9       0.49      0.22      0.30      1755\n",
            "          10       0.23      0.25      0.24       306\n",
            "          11       0.30      0.35      0.32      1035\n",
            "          12       0.69      0.56      0.62      2475\n",
            "          13       0.57      0.25      0.34       933\n",
            "          14       0.33      0.09      0.14       759\n",
            "          15       0.31      0.39      0.34      1851\n",
            "          16       0.67      0.04      0.07        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.46      0.48      0.47      4770\n",
            "          19       0.69      0.49      0.57      1758\n",
            "          20       0.33      0.09      0.15       426\n",
            "          21       0.71      0.27      0.39       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.61      0.33      0.43      4701\n",
            "          24       0.57      0.62      0.60      1203\n",
            "          25       0.58      0.60      0.59       630\n",
            "\n",
            "   micro avg       0.60      0.46      0.52     58167\n",
            "   macro avg       0.51      0.32      0.37     58167\n",
            "weighted avg       0.61      0.46      0.50     58167\n",
            " samples avg       0.60      0.51      0.51     58167\n",
            "\n",
            "Epoch 21/30, Loss: 0.028785853510638202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11916057614224046\n",
            "Precision: 0.47479007002306484\n",
            "Recall: 0.3322487373513934\n",
            "F1-Score: 0.36664462016004296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.36      0.45      3132\n",
            "           1       0.43      0.48      0.46      2463\n",
            "           2       0.41      0.52      0.46       918\n",
            "           3       0.41      0.07      0.12      1233\n",
            "           4       0.60      0.62      0.61      7833\n",
            "           5       0.55      0.57      0.56      3489\n",
            "           6       0.80      0.52      0.63      1887\n",
            "           7       0.73      0.61      0.66     12426\n",
            "           8       0.33      0.63      0.44      1554\n",
            "           9       0.44      0.33      0.37      1755\n",
            "          10       0.33      0.08      0.12       306\n",
            "          11       0.38      0.18      0.24      1035\n",
            "          12       0.76      0.46      0.57      2475\n",
            "          13       0.50      0.36      0.42       933\n",
            "          14       0.33      0.10      0.16       759\n",
            "          15       0.48      0.10      0.17      1851\n",
            "          16       0.22      0.04      0.06        57\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.60      0.17      0.26      4770\n",
            "          19       0.74      0.41      0.52      1758\n",
            "          20       0.20      0.20      0.20       426\n",
            "          21       0.64      0.36      0.46       573\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.65      0.26      0.37      4701\n",
            "          24       0.61      0.59      0.60      1203\n",
            "          25       0.58      0.63      0.60       630\n",
            "\n",
            "   micro avg       0.59      0.45      0.51     58167\n",
            "   macro avg       0.47      0.33      0.37     58167\n",
            "weighted avg       0.60      0.45      0.49     58167\n",
            " samples avg       0.60      0.49      0.50     58167\n",
            "\n",
            "Epoch 22/30, Loss: 0.02584653340416752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "VWtsIHx6w0T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "save_dir = \"/content/Model/Models-Train-1\"\n",
        "load_path = os.path.join(save_dir, '8_model.pth')\n",
        "\n",
        "\n",
        "model = models.resnet101(pretrained=False)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, len(unique_labels)),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "model.load_state_dict(torch.load(load_path))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "n3WA2jmvwinp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store predicted and ground truth labels\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Iterate through the test set and make predictions\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted_labels.extend(outputs.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "2xfv0nHIxEAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels[0]"
      ],
      "metadata": {
        "id": "xD6r2Tetx9Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "\n",
        "binary_predictions = []\n",
        "\n",
        "for sample_logits in predicted_labels:\n",
        "    binary_sample_predictions = [1 if value >= threshold else 0 for value in sample_logits]\n",
        "    binary_predictions.append(binary_sample_predictions)"
      ],
      "metadata": {
        "id": "cjZ_uU9My8nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_predictions[1000]"
      ],
      "metadata": {
        "id": "jpFmDp3KzPwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(true_labels, binary_predictions)\n",
        "precision = precision_score(true_labels, binary_predictions, average='macro')\n",
        "recall = recall_score(true_labels, binary_predictions, average='macro')\n",
        "f1 = f1_score(true_labels, binary_predictions, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(classification_report(true_labels, binary_predictions))"
      ],
      "metadata": {
        "id": "poAMnH0lximL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aibnGr-BxTny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}