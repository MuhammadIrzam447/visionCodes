{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VqotBnmCXM6s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/visionCodes/blob/master/mm_imdb(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Dataset(s)/mm-imdb/fused"
      ],
      "metadata": {
        "id": "xZY4W75rjsk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmF1zNcPTGga"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1dxd2pySfCIDJYG7qMtuJre8ph068xc1X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1sYR9EgHkM0oiGRQVlFQCyHO8kMRJ4ibQ"
      ],
      "metadata": {
        "id": "KKm0C_4oTUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1X4cmMYRjxXFomCJ1adMhPNMYtd4WeDHP"
      ],
      "metadata": {
        "id": "WQeDAAyZ0WLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1yAeNEPXD3LNxmtSnC09jEg0vEDc1qiaq"
      ],
      "metadata": {
        "id": "Hou-hwbv0W6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test.zip"
      ],
      "metadata": {
        "id": "Q--gX0z1yYPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "gc3k8cZ10bwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset Preparation"
      ],
      "metadata": {
        "id": "VqotBnmCXM6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"\"\n",
        "labels_file = ''\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        image_file_paths.append(image_path)\n",
        "        genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "O2DdTX5_XNV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_paths"
      ],
      "metadata": {
        "id": "nXDErAZjdJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels"
      ],
      "metadata": {
        "id": "PWOIg0hTdKvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels_set = set()\n",
        "\n",
        "for labels in genre_labels:\n",
        "    unique_labels_set.update(labels)\n",
        "\n",
        "unique_labels = sorted(list(unique_labels_set))"
      ],
      "metadata": {
        "id": "WnWdzeiWXXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels"
      ],
      "metadata": {
        "id": "rB1rz-dwZgxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_labels)"
      ],
      "metadata": {
        "id": "gbg9-ae_zi0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "\n",
        "for labels in genre_labels:\n",
        "    for label in labels:\n",
        "        label_counts[label] += 1"
      ],
      "metadata": {
        "id": "yslKvYyH2tQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts"
      ],
      "metadata": {
        "id": "3DMfkmDS20rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in unique_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "weVX9tVdZhxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels[1]"
      ],
      "metadata": {
        "id": "5BdzoGhlZ1uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels[1]"
      ],
      "metadata": {
        "id": "1ozp7IfHZ2-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomMultiLabelDataset(Dataset):\n",
        "    def __init__(self, image_file_paths, multi_encoded_labels, transform=None):\n",
        "        self.image_file_paths = image_file_paths\n",
        "        self.multi_encoded_labels = multi_encoded_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_file_paths[idx]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        labels = self.multi_encoded_labels[idx]\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, labels"
      ],
      "metadata": {
        "id": "uprw1hgjbHji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset\n",
        "train_dataset = CustomMultiLabelDataset(image_file_paths, multi_hot_labels)"
      ],
      "metadata": {
        "id": "pjHkp2KZblJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "6djdqSdHdylD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "XY0b1aLgd1Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataset))"
      ],
      "metadata": {
        "id": "dTLW7GYAGaNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "dkFsHZh1NtE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(examples):\n",
        "    # inputs = image_processor([img.convert(\"RGB\") for img in examples], return_tensors=\"pt\")\n",
        "    inputs = image_processor(examples, return_tensors=\"pt\")\n",
        "    inputs[\"labels\"] = examples[\"label\"]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "W9pLux06Nn75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [transform(item) for item in train_dataset]"
      ],
      "metadata": {
        "id": "Kzb6cyXMNpVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataset))"
      ],
      "metadata": {
        "id": "pZ_ADGQcOV2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "KCfJth3zqdZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Dataset"
      ],
      "metadata": {
        "id": "icrHCsUfu8dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/test\"\n",
        "labels_file = '/content/test_label.txt'\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        image_file_paths.append(image_path)\n",
        "        genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "_8eHNFXOqgax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_file_paths"
      ],
      "metadata": {
        "id": "t_n7AqzSAPsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_labels_set = set()\n",
        "\n",
        "# for labels in genre_labels:\n",
        "#     unique_labels_set.update(labels)\n",
        "\n",
        "# unique_labels = sorted(list(unique_labels_set))"
      ],
      "metadata": {
        "id": "yOWH3My0qkzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_labels)"
      ],
      "metadata": {
        "id": "dXQLBhzpuv1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in unique_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "GsgQXllaqo7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Dataset"
      ],
      "metadata": {
        "id": "27JUbagnvJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_image_file_paths = []\n",
        "train_genre_labels = []\n",
        "\n",
        "train_image_folder_add = \"/content/test\"\n",
        "train_labels_file = '/content/test_label.txt'\n",
        "\n",
        "with open(train_labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(train_image_folder_add, filename)\n",
        "        train_image_file_paths.append(image_path)\n",
        "        train_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "SGASG2u5vIGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels_set = set()\n",
        "\n",
        "for labels in train_genre_labels:\n",
        "    unique_labels_set.update(labels)\n",
        "\n",
        "unique_labels = sorted(list(unique_labels_set))"
      ],
      "metadata": {
        "id": "7Xi19i0Avxfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(unique_labels)\n",
        "label2id = {label: str(i) for i, label in enumerate(unique_labels)}\n",
        "id2label = {str(i): label for i, label in enumerate(unique_labels)}"
      ],
      "metadata": {
        "id": "3erAiX-pv1PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "IYSgaj2cwKDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels"
      ],
      "metadata": {
        "id": "TX4BGI9_wNfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in unique_labels]\n",
        "    train_multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "fkFtTj2FvWpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Datasets"
      ],
      "metadata": {
        "id": "wPeiQ6yyvNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "G9Nsa_BDrGNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {'image': train_image_file_paths, 'label': train_multi_hot_labels}\n",
        "ds_train = Dataset.from_dict(train_data)\n",
        "\n",
        "val_data = {'image': image_file_paths, 'label': multi_hot_labels}\n",
        "ds_val = Dataset.from_dict(val_data)\n"
      ],
      "metadata": {
        "id": "a4mLnUT7qd5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train"
      ],
      "metadata": {
        "id": "3SjM0TVurJGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "O8mdfwrqwykE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train['image'][0], ds_val['image'][0]"
      ],
      "metadata": {
        "id": "R5kP5p4_r008"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = ds.features[\"label\"]\n",
        "labels = unique_labels\n",
        "labels"
      ],
      "metadata": {
        "id": "iZAsVZXkrMHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets\n",
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import *\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Yjo1uO85sPhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "T1YZ7kVesVM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "qXK14nDosWFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as pil\n",
        "\n",
        "def transform(examples):\n",
        "  # inputs = image_processor([Image.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs = image_processor([pil.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs[\"labels\"] = examples[\"label\"]\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "bpeUOPS2v_qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ds_train.with_transform(transform)\n",
        "val_dataset = ds_val.with_transform(transform)"
      ],
      "metadata": {
        "id": "DZUEGqDlwEZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "WgMgw6nswEo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "id": "2cC5DlJQxNzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[2000]\n",
        "# img = sample[\"pixel_values\"]\n",
        "# filename = os.path.basename(img.filename)\n",
        "# print(f\"File Name: {filename}\")"
      ],
      "metadata": {
        "id": "Yu09sABJUxNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "u9Yfq17FYtIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataset:\n",
        "  print(item['pixel_values'].shape)\n",
        "  print(item[\"labels\"])\n",
        "  break"
      ],
      "metadata": {
        "id": "GMi1dn5qzHn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
        "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "  }"
      ],
      "metadata": {
        "id": "6J-LWUv_wE48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation"
      ],
      "metadata": {
        "id": "nNN2igTOxdjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ViT model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels= len(unique_labels),\n",
        "    label2id = {label: str(i) for i, label in enumerate(unique_labels)},\n",
        "    id2label = {str(i): label for i, label in enumerate(unique_labels)},\n",
        "    problem_type = \"multi_label_classification\",\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ge9TkjxDvU7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "QSaA0l0kvfD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset_loader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "H9a305Thv487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "pDTtvcPav0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"/content/Untitled Folder\"\n",
        "summary_writer = SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "0u-AcYYPBCIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qxzkS9aDBEP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps = num_epochs * len(train_dataset_loader)\n",
        "n_valid_steps = len(valid_dataset_loader)\n",
        "current_step = 0"
      ],
      "metadata": {
        "id": "dbdQh7a9BMQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps , n_valid_steps"
      ],
      "metadata": {
        "id": "0zupZcnNxti1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logging, eval & save steps\n",
        "save_steps = 1000"
      ],
      "metadata": {
        "id": "aS9zwwA3BXUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "  accuracy_score = accuracy.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
        "  f1_score = f1.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids, average=\"macro\")\n",
        "  return {**accuracy_score, **f1_score}"
      ],
      "metadata": {
        "id": "f7H1EL2TBVPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    progress_bar = tqdm(range(current_step, n_train_steps), \"Training\", dynamic_ncols=True, ncols=80)\n",
        "\n",
        "    for batch in train_dataset_loader:\n",
        "      if (current_step+1) % save_steps == 0:\n",
        "        print()\n",
        "        print(f\"Validation at step {current_step}...\")\n",
        "        print()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        predictions, labels = [], []\n",
        "        valid_loss = 0\n",
        "\n",
        "        for batch in valid_dataset_loader:\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            label_ids = batch[\"labels\"].to(device).float()\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits.detach().cpu()\n",
        "\n",
        "            # predictions.extend(logits.argmax(dim=-1).tolist())\n",
        "            # labels.extend(label_ids.tolist())\n",
        "            predictions.extend((outputs > 0.5).int().cpu().numpy())\n",
        "            labels.extend(labels.int().cpu().numpy())\n",
        "\n",
        "        # eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
        "        # metrics = compute_metrics(eval_prediction)\n",
        "        print()\n",
        "        print(f\"Epoch: {epoch}, Step: {current_step}, Train Loss: {train_loss / save_steps:.4f}, \" +\n",
        "              f\"Valid Loss: {valid_loss / n_valid_steps:.4f}\") # , Accuracy: {metrics['accuracy']}, \" + f\"F1 Score: {metrics['f1']}\")\n",
        "        print()\n",
        "\n",
        "        # summary_writer.add_scalar(\"valid_loss\", valid_loss / n_valid_steps, global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"accuracy\", metrics[\"accuracy\"], global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"f1\", metrics[\"f1\"], global_step=current_step)\n",
        "\n",
        "        model.save_pretrained(f\"./vit-base-food/checkpoint-{current_step}\")\n",
        "        image_processor.save_pretrained(f\"./vit-base-food/checkpoint-{current_step}\")\n",
        "\n",
        "        accuracy = accuracy_score(true_labels, predictions)\n",
        "        precision = precision_score(true_labels, predictions, average='macro')\n",
        "        recall = recall_score(true_labels, predictions, average='macro')\n",
        "        f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-Score: {f1}\")\n",
        "        print(classification_report(true_labels, predictions))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, valid_loss = 0, 0\n",
        "\n",
        "      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device).float()\n",
        "\n",
        "      outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_v = loss.item()\n",
        "      train_loss += loss_v\n",
        "\n",
        "      current_step += 1\n",
        "      progress_bar.update(1)\n",
        "      summary_writer.add_scalar(\"train_loss\", loss_v, global_step=current_step)"
      ],
      "metadata": {
        "id": "PXHxhHIqCGR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in valid_dataset_loader:\n",
        "            # get the batch\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            label_ids = batch[\"labels\"].to(device).float()\n",
        "            print(label_ids)\n",
        "            break"
      ],
      "metadata": {
        "id": "qRnkOZ5xl20q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez_RluKbmJAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}